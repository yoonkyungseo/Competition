{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# EDA\n",
    "#import klib\n",
    "\n",
    "# Preprocessing & Feature Engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from scipy.stats.mstats import gmean\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Modeling\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Utility\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import Image\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import platform\n",
    "from itertools import combinations\n",
    "\n",
    "import gc\n",
    "import re\n",
    "from typing import List ,Dict, Tuple\n",
    "\n",
    "# 한글 폰트 설정\n",
    "from statsmodels import robust\n",
    "from matplotlib import font_manager, rc\n",
    "%matplotlib inline\n",
    "\n",
    "import platform\n",
    "your_os = platform.system()\n",
    "if your_os == 'Linux':\n",
    "    rc('font', family='NanumGothic')\n",
    "elif your_os == 'Windows':\n",
    "    ttf = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "    font_name = font_manager.FontProperties(fname=ttf).get_name()\n",
    "    rc('font', family=font_name)\n",
    "elif your_os == 'Darwin':\n",
    "    rc('font', family='AppleGothic')\n",
    "rc('axes', unicode_minus=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((501951, 35), (46404, 34))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "d_code = pd.read_csv('속성_D_코드.csv')\n",
    "h_code = pd.read_csv('속성_H_코드.csv')\n",
    "l_code = pd.read_csv('속성_L_코드.csv')\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d_l_match_yn</th>\n",
       "      <th>d_m_match_yn</th>\n",
       "      <th>d_s_match_yn</th>\n",
       "      <th>h_l_match_yn</th>\n",
       "      <th>h_m_match_yn</th>\n",
       "      <th>h_s_match_yn</th>\n",
       "      <th>person_attribute_a</th>\n",
       "      <th>person_attribute_a_1</th>\n",
       "      <th>person_attribute_b</th>\n",
       "      <th>person_prefer_c</th>\n",
       "      <th>person_prefer_d_1</th>\n",
       "      <th>person_prefer_d_2</th>\n",
       "      <th>person_prefer_d_3</th>\n",
       "      <th>person_prefer_e</th>\n",
       "      <th>person_prefer_f</th>\n",
       "      <th>person_prefer_g</th>\n",
       "      <th>person_prefer_h_1</th>\n",
       "      <th>person_prefer_h_2</th>\n",
       "      <th>person_prefer_h_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>275</td>\n",
       "      <td>370</td>\n",
       "      <td>369</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>181</td>\n",
       "      <td>175</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>101</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>464</td>\n",
       "      <td>175</td>\n",
       "      <td>452</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>263</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>703</td>\n",
       "      <td>705</td>\n",
       "      <td>704</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>227</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>275</td>\n",
       "      <td>370</td>\n",
       "      <td>369</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>214</td>\n",
       "      <td>210</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  d_l_match_yn  d_m_match_yn  d_s_match_yn  h_l_match_yn  h_m_match_yn  \\\n",
       "0   0          True          True          True         False         False   \n",
       "1   1         False         False         False          True          True   \n",
       "2   2         False         False         False          True         False   \n",
       "3   3         False         False         False          True         False   \n",
       "4   4          True          True          True         False         False   \n",
       "\n",
       "   h_s_match_yn  person_attribute_a  person_attribute_a_1  person_attribute_b  \\\n",
       "0         False                   1                     4                   3   \n",
       "1         False                   1                     3                   4   \n",
       "2         False                   2                     0                   3   \n",
       "3         False                   2                     0                   2   \n",
       "4         False                   1                     3                   4   \n",
       "\n",
       "   person_prefer_c  person_prefer_d_1  person_prefer_d_2  person_prefer_d_3  \\\n",
       "0                5                275                370                369   \n",
       "1                1                114                181                175   \n",
       "2                5                464                175                452   \n",
       "3                5                703                705                704   \n",
       "4                5                275                370                369   \n",
       "\n",
       "   person_prefer_e  person_prefer_f  person_prefer_g  person_prefer_h_1  \\\n",
       "0                8                1                1                  4   \n",
       "1                4                1                1                131   \n",
       "2                3                1                1                 54   \n",
       "3                3                1                1                 72   \n",
       "4                4                1                1                214   \n",
       "\n",
       "   person_prefer_h_2  person_prefer_h_3  \n",
       "0                 95                 59  \n",
       "1                101                 96  \n",
       "2                263                 56  \n",
       "3                227                  2  \n",
       "4                210                209  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[:, :20].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents_attribute_i</th>\n",
       "      <th>contents_attribute_a</th>\n",
       "      <th>contents_attribute_j_1</th>\n",
       "      <th>contents_attribute_j</th>\n",
       "      <th>contents_attribute_c</th>\n",
       "      <th>contents_attribute_k</th>\n",
       "      <th>contents_attribute_l</th>\n",
       "      <th>contents_attribute_d</th>\n",
       "      <th>contents_attribute_m</th>\n",
       "      <th>contents_attribute_e</th>\n",
       "      <th>contents_attribute_h</th>\n",
       "      <th>person_rn</th>\n",
       "      <th>contents_rn</th>\n",
       "      <th>contents_open_dt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1608</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>139</td>\n",
       "      <td>618822</td>\n",
       "      <td>354805</td>\n",
       "      <td>2020-01-17 12:09:36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1608</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>133</td>\n",
       "      <td>571659</td>\n",
       "      <td>346213</td>\n",
       "      <td>2020-06-18 17:48:52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>399816</td>\n",
       "      <td>206408</td>\n",
       "      <td>2020-07-08 20:00:10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1608</td>\n",
       "      <td>275</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>827967</td>\n",
       "      <td>572323</td>\n",
       "      <td>2020-01-13 18:09:34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1608</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>831614</td>\n",
       "      <td>573899</td>\n",
       "      <td>2020-03-09 20:39:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   contents_attribute_i  contents_attribute_a  contents_attribute_j_1  \\\n",
       "0                     3                     3                      10   \n",
       "1                     1                     3                       5   \n",
       "2                     3                     1                      10   \n",
       "3                     1                     3                       5   \n",
       "4                     1                     1                      10   \n",
       "\n",
       "   contents_attribute_j  contents_attribute_c  contents_attribute_k  \\\n",
       "0                     2                     1                     2   \n",
       "1                     1                     1                     2   \n",
       "2                     2                     1                     1   \n",
       "3                     1                     1                     2   \n",
       "4                     2                     1                     2   \n",
       "\n",
       "   contents_attribute_l  contents_attribute_d  contents_attribute_m  \\\n",
       "0                  1608                   275                     1   \n",
       "1                  1608                   275                     1   \n",
       "2                  1600                    94                     1   \n",
       "3                  1608                   275                     5   \n",
       "4                  1608                   275                     1   \n",
       "\n",
       "   contents_attribute_e  contents_attribute_h  person_rn  contents_rn  \\\n",
       "0                     4                   139     618822       354805   \n",
       "1                     4                   133     571659       346213   \n",
       "2                     4                    53     399816       206408   \n",
       "3                     3                    74     827967       572323   \n",
       "4                     4                    74     831614       573899   \n",
       "\n",
       "      contents_open_dt  target  \n",
       "0  2020-01-17 12:09:36       1  \n",
       "1  2020-06-18 17:48:52       0  \n",
       "2  2020-07-08 20:00:10       0  \n",
       "3  2020-01-13 18:09:34       0  \n",
       "4  2020-03-09 20:39:22       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[:, 20:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### D_code\n",
    "- 코드 사이에 숫자가 밑의 코드로 갈린다\n",
    "- 이걸 피처로 어떻게 나타낼 수 있을까"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "속성 D 대분류코드\n",
       "1                                            [2, 56, 189]\n",
       "216                             [217, 220, 231, 274, 297]\n",
       "377                             [378, 439, 450, 473, 477]\n",
       "482                                                 [482]\n",
       "522                                            [523, 603]\n",
       "618                        [619, 644, 659, 690, 708, 716]\n",
       "744                                            [745, 824]\n",
       "864                                                 [864]\n",
       "926     [927, 1000, 1053, 1093, 1104, 1137, 1169, 1193...\n",
       "1235                                               [1235]\n",
       "1258                                               [1258]\n",
       "Name: 속성 D 중분류코드, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_code.groupby('속성 D 대분류코드')['속성 D 중분류코드'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "속성 D 중분류코드\n",
       "2                              [3, 6, 16, 29, 37, 43]\n",
       "56            [57, 58, 63, 72, 83, 91, 109, 123, 152]\n",
       "189                                   [190, 197, 210]\n",
       "217                                             [217]\n",
       "220                                        [221, 224]\n",
       "231                    [232, 238, 242, 258, 270, 273]\n",
       "274                                             [274]\n",
       "297     [298, 312, 315, 332, 340, 353, 356, 359, 368]\n",
       "378                         [379, 382, 396, 397, 431]\n",
       "439                                        [440, 446]\n",
       "450                                   [451, 463, 470]\n",
       "473                                             [473]\n",
       "477                                             [477]\n",
       "482               [483, 488, 489, 490, 494, 495, 509]\n",
       "523               [524, 537, 540, 547, 560, 586, 600]\n",
       "603                                             [603]\n",
       "619                                        [620, 636]\n",
       "644                              [645, 652, 655, 656]\n",
       "659                                        [660, 677]\n",
       "690                                        [691, 703]\n",
       "708                                             [708]\n",
       "716                                        [717, 735]\n",
       "745               [746, 747, 775, 782, 783, 810, 815]\n",
       "824                              [825, 831, 847, 853]\n",
       "864                    [865, 884, 901, 909, 915, 923]\n",
       "927               [928, 951, 961, 982, 985, 988, 996]\n",
       "1000             [1001, 1008, 1017, 1026, 1036, 1042]\n",
       "1053             [1054, 1062, 1077, 1078, 1083, 1086]\n",
       "1093                                     [1094, 1098]\n",
       "1104                               [1105, 1111, 1129]\n",
       "1137                         [1138, 1150, 1158, 1164]\n",
       "1169                               [1170, 1173, 1180]\n",
       "1193                   [1194, 1204, 1211, 1217, 1220]\n",
       "1227                                           [1227]\n",
       "1235                   [1236, 1244, 1248, 1251, 1254]\n",
       "1258                                           [1258]\n",
       "Name: 속성 D 소분류코드, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_code.groupby('속성 D 중분류코드')['속성 D 소분류코드'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### H_code\n",
    "* 중분류가 대분류에 이어지는 숫자 형태\n",
    "* 대분류랑 코드는 D와 같은 형태인데 중분류가 너무 눈치없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>속성 H 코드</th>\n",
       "      <th>속성 H 중분류코드</th>\n",
       "      <th>속성 H 대분류코드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>316</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>317</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>318</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>319</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>309</td>\n",
       "      <td>566</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>310</td>\n",
       "      <td>567</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>311</td>\n",
       "      <td>568</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>313</td>\n",
       "      <td>569</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>314</td>\n",
       "      <td>570</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     속성 H 코드  속성 H 중분류코드  속성 H 대분류코드\n",
       "0          2         315           1\n",
       "1          4         316           3\n",
       "2          5         317           3\n",
       "3          6         318           3\n",
       "4          7         319           3\n",
       "..       ...         ...         ...\n",
       "289      309         566         308\n",
       "290      310         567         308\n",
       "291      311         568         308\n",
       "292      313         569         312\n",
       "293      314         570         314\n",
       "\n",
       "[294 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "속성 H 대분류코드\n",
       "1                                                  [315]\n",
       "3      [316, 317, 318, 319, 320, 321, 322, 323, 324, ...\n",
       "30     [342, 343, 344, 345, 346, 347, 348, 349, 350, ...\n",
       "48         [359, 360, 361, 362, 363, 364, 365, 366, 367]\n",
       "58     [368, 369, 370, 371, 372, 373, 374, 375, 376, ...\n",
       "71                        [379, 380, 381, 382, 383, 384]\n",
       "78                        [385, 386, 387, 388, 389, 390]\n",
       "85                        [391, 392, 393, 394, 395, 396]\n",
       "92                                                 [397]\n",
       "94     [398, 399, 400, 401, 402, 403, 404, 405, 406, ...\n",
       "149    [432, 433, 434, 435, 436, 437, 438, 439, 440, ...\n",
       "169    [451, 452, 453, 454, 455, 456, 457, 458, 459, ...\n",
       "188    [463, 464, 465, 466, 467, 468, 469, 470, 471, ...\n",
       "208    [480, 481, 482, 483, 484, 485, 486, 487, 488, ...\n",
       "226    [495, 496, 497, 498, 499, 500, 501, 502, 503, ...\n",
       "250    [518, 519, 520, 521, 522, 523, 524, 525, 526, ...\n",
       "277    [542, 543, 544, 545, 546, 547, 548, 549, 550, ...\n",
       "302                            [561, 562, 563, 564, 565]\n",
       "308                                      [566, 567, 568]\n",
       "312                                                [569]\n",
       "314                                                [570]\n",
       "Name: 속성 H 중분류코드, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_code.groupby('속성 H 대분류코드')['속성 H 중분류코드'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "속성 H 대분류코드\n",
       "1                                                    [2]\n",
       "3      [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,...\n",
       "30     [31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 4...\n",
       "48                  [49, 50, 51, 52, 53, 54, 55, 56, 57]\n",
       "58      [59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70]\n",
       "71                              [72, 73, 74, 75, 76, 77]\n",
       "78                              [79, 80, 81, 82, 83, 84]\n",
       "85                              [86, 87, 88, 89, 90, 91]\n",
       "92                                                  [93]\n",
       "94     [95, 96, 97, 98, 99, 100, 101, 102, 103, 104, ...\n",
       "149    [150, 151, 152, 153, 154, 155, 156, 157, 158, ...\n",
       "169    [170, 171, 172, 173, 174, 175, 176, 177, 178, ...\n",
       "188    [189, 190, 191, 192, 193, 194, 195, 196, 197, ...\n",
       "208    [209, 210, 211, 212, 213, 214, 215, 216, 217, ...\n",
       "226    [227, 228, 229, 230, 231, 232, 233, 234, 235, ...\n",
       "250    [251, 252, 253, 254, 255, 256, 257, 258, 259, ...\n",
       "277    [278, 279, 280, 281, 282, 283, 284, 285, 286, ...\n",
       "302                            [303, 304, 305, 306, 307]\n",
       "308                                      [309, 310, 311]\n",
       "312                                                [313]\n",
       "314                                                [314]\n",
       "Name: 속성 H 코드, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_code.groupby('속성 H 대분류코드')['속성 H 코드'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "속성 H 중분류코드\n",
       "315      [2]\n",
       "316      [4]\n",
       "317      [5]\n",
       "318      [6]\n",
       "319      [7]\n",
       "       ...  \n",
       "566    [309]\n",
       "567    [310]\n",
       "568    [311]\n",
       "569    [313]\n",
       "570    [314]\n",
       "Name: 속성 H 코드, Length: 256, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_code.groupby('속성 H 중분류코드')['속성 H 코드'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### L_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>속성 L 코드</th>\n",
       "      <th>속성 L 세분류코드</th>\n",
       "      <th>속성 L 소분류코드</th>\n",
       "      <th>속성 L 중분류코드</th>\n",
       "      <th>속성 L 대분류코드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   속성 L 코드  속성 L 세분류코드  속성 L 소분류코드  속성 L 중분류코드  속성 L 대분류코드\n",
       "0        1           1           1           1        2004\n",
       "1        2           2           2           1        2004\n",
       "2        3           3           2           1        2004\n",
       "3        4           3           2           1        2004\n",
       "4        5           5           2           1        2004"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "속성 L 대분류코드\n",
       "2004                                    [1, 42, 53, 2004]\n",
       "2005                               [67, 74, 81, 95, 2005]\n",
       "2006    [99, 168, 183, 187, 229, 257, 272, 295, 321, 3...\n",
       "2007                                          [869, 2007]\n",
       "2008                           [887, 893, 901, 925, 2008]\n",
       "2009                                     [930, 954, 2009]\n",
       "2010                             [1003, 1021, 1152, 2010]\n",
       "2011                       [1271, 1301, 1316, 1323, 2011]\n",
       "2012                                   [1353, 1365, 2012]\n",
       "2013           [1397, 1417, 1435, 1446, 1458, 1467, 2013]\n",
       "2014                             [1480, 1504, 1522, 2014]\n",
       "2015                                         [1538, 2015]\n",
       "2016                       [1556, 1572, 1605, 1623, 2016]\n",
       "2017                             [1645, 1658, 1688, 2017]\n",
       "2018                                         [1713, 2018]\n",
       "2019                                         [1752, 2019]\n",
       "2020                                   [1810, 1832, 2020]\n",
       "2021                                   [1852, 1879, 2021]\n",
       "2022                             [1918, 1941, 1962, 2022]\n",
       "2023                                   [1988, 1992, 2023]\n",
       "2024                                         [1999, 2024]\n",
       "2025                                               [2025]\n",
       "Name: 속성 L 중분류코드, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_code.groupby('속성 L 대분류코드')['속성 L 중분류코드'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "속성 L 중분류코드\n",
       "1       [1, 2, 18, 30, 33, 39]\n",
       "42                    [42, 43]\n",
       "53                [53, 54, 60]\n",
       "67                [67, 68, 71]\n",
       "74                [74, 75, 78]\n",
       "                 ...          \n",
       "2021                    [2021]\n",
       "2022                    [2022]\n",
       "2023                    [2023]\n",
       "2024                    [2024]\n",
       "2025                    [2025]\n",
       "Name: 속성 L 소분류코드, Length: 99, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_code.groupby('속성 L 중분류코드')['속성 L 소분류코드'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "속성 L 소분류코드\n",
       "1                        [1]\n",
       "2       [2, 3, 5, 9, 12, 14]\n",
       "18      [18, 19, 22, 24, 27]\n",
       "30                  [30, 31]\n",
       "33              [33, 34, 37]\n",
       "                ...         \n",
       "2021                  [2021]\n",
       "2022                  [2022]\n",
       "2023                  [2023]\n",
       "2024                  [2024]\n",
       "2025                  [2025]\n",
       "Name: 속성 L 세분류코드, Length: 332, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_code.groupby('속성 L 소분류코드')['속성 L 세분류코드'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing & engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### person_rn, contents_rn 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['person_contents_mul'] = train['person_rn'] * train['contents_rn']\n",
    "test['person_contents_mul'] = test['person_rn'] * test['contents_rn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['person_contents_sum'] = train['person_rn'] + train['contents_rn']\n",
    "test['person_contents_sum'] = test['person_rn'] + test['contents_rn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contents_open_dt 관련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['contents_open_dt'] = pd.to_datetime(train['contents_open_dt'])\n",
    "test['contents_open_dt'] = pd.to_datetime(test['contents_open_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['contents_open_hour'] = train['contents_open_dt'].dt.hour\n",
    "test['contents_open_hour'] = test['contents_open_dt'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hour = train.groupby('contents_open_hour').target.sum() / train.groupby('contents_open_hour').target.size()\n",
    "train['contents_open_hour'] = train['contents_open_hour'].apply(lambda x: train_hour[x])\n",
    "test['contents_open_hour'] = test['contents_open_hour'].apply(lambda x: train_hour[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리\n",
    "- 코드표 결합\n",
    "- 같은 범주 일치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_code.columns = ['attribute_d', 'attribute_d_d', 'attribute_d_s', 'attribute_d_m', 'attribute_d_l']\n",
    "h_code.columns = ['attribute_h', 'attribute_h_m', 'attribute_h_l']\n",
    "l_code.columns = ['attribute_l', 'attribute_l_d', 'attribute_l_s', 'attribute_l_m', 'attribute_l_l']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_codes(df : pd.DataFrame, \n",
    "                df_code : pd.DataFrame,\n",
    "                col : str) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df_code = df_code.copy()\n",
    "    df_code = df_code.add_prefix(f\"{col}_\")\n",
    "    df_code.columns.values[0] = col\n",
    "    return pd.merge(df, df_code, how=\"left\", on=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(\n",
    "                    df : pd.DataFrame, \n",
    "                    is_train : bool = True, \n",
    "                    cols_merge : List[Tuple[str, pd.DataFrame]] = [], \n",
    "                    cols_equi : List[Tuple[str, str]] = [] ,\n",
    "                    cols_drop : List[str] = ['id', 'person_prefer_f', 'person_prefer_g', 'contents_open_dt']\n",
    "                    ) -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "    df = df.copy()\n",
    "\n",
    "    y_data = None\n",
    "    if is_train:\n",
    "        y_data = df['target'].to_numpy()\n",
    "        df = df.drop(columns='target')\n",
    "\n",
    "    for col, df_code in cols_merge:\n",
    "        df = merge_codes(df, df_code, col)\n",
    "\n",
    "    cols = df.select_dtypes(bool).columns.tolist()\n",
    "    df[cols] = df[cols].astype(int)\n",
    "\n",
    "    for col1, col2 in cols_equi:\n",
    "        df[f'{col1}_{col2}'] = (df[col1] == df[col2]).astype(int)\n",
    "        \n",
    "    df = df.drop(columns=cols_drop)\n",
    "    return (df, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소분류 중분류 대분류 속성코드 merge 컬럼명 및 데이터 프레임 리스트\n",
    "cols_merge = [\n",
    "              ('person_prefer_d_1', d_code),\n",
    "              ('person_prefer_d_2', d_code),\n",
    "              ('person_prefer_d_3', d_code),\n",
    "              ('contents_attribute_d', d_code),\n",
    "              ('person_prefer_h_1', h_code),\n",
    "              ('person_prefer_h_2', h_code),\n",
    "              ('person_prefer_h_3', h_code),\n",
    "              ('contents_attribute_h', h_code),\n",
    "              ('contents_attribute_l', l_code),\n",
    "]\n",
    "\n",
    "# 회원 속성과 콘텐츠 속성의 동일한 코드 여부에 대한 컬럼명 리스트\n",
    "cols_equi = [\n",
    "\n",
    "    ('contents_attribute_a', 'person_attribute_a'),\n",
    "    ('contents_attribute_c', 'person_prefer_c'),\n",
    "    ('contents_attribute_e', 'person_prefer_e'),\n",
    "\n",
    "    ('person_prefer_d_1_attribute_d_s', 'contents_attribute_d_attribute_d_s'),\n",
    "    ('person_prefer_d_1_attribute_d_m', 'contents_attribute_d_attribute_d_m'),\n",
    "    ('person_prefer_d_2', 'contents_attribute_d'),\n",
    "    ('person_prefer_d_2_attribute_d_d', 'contents_attribute_d_attribute_d_d'),\n",
    "    ('person_prefer_d_2_attribute_d_s', 'contents_attribute_d_attribute_d_s'),\n",
    "    ('person_prefer_d_2_attribute_d_m', 'contents_attribute_d_attribute_d_m'),\n",
    "    ('person_prefer_d_2_attribute_d_l', 'contents_attribute_d_attribute_d_l'),\n",
    "    ('person_prefer_d_3', 'contents_attribute_d'),\n",
    "    ('person_prefer_d_3_attribute_d_d', 'contents_attribute_d_attribute_d_d'),\n",
    "    ('person_prefer_d_3_attribute_d_s', 'contents_attribute_d_attribute_d_s'),\n",
    "    ('person_prefer_d_3_attribute_d_m', 'contents_attribute_d_attribute_d_m'),\n",
    "    ('person_prefer_d_3_attribute_d_l', 'contents_attribute_d_attribute_d_l'),\n",
    "\n",
    "    ('person_prefer_h_2', 'contents_attribute_h'),\n",
    "    ('person_prefer_h_2_attribute_h_m', 'contents_attribute_h_attribute_h_m'),\n",
    "    ('person_prefer_h_2_attribute_h_l', 'contents_attribute_h_attribute_h_l'),\n",
    "    ('person_prefer_h_3', 'contents_attribute_h'),\n",
    "    ('person_prefer_h_3_attribute_h_m', 'contents_attribute_h_attribute_h_m'),\n",
    "    ('person_prefer_h_3_attribute_h_l', 'contents_attribute_h_attribute_h_l'),\n",
    "\n",
    "]\n",
    "\n",
    "# 학습에 필요없는 컬럼 리스트\n",
    "cols_drop = ['id', 'person_prefer_f', 'person_prefer_g', 'contents_rn', 'contents_open_dt', 'person_rn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((501951, 80), (501951,), (46404, 80))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = preprocess_data(train, cols_merge=cols_merge, cols_equi=cols_equi, cols_drop=cols_drop)\n",
    "x_test, _ = preprocess_data(test, is_train=False, cols_merge=cols_merge, cols_equi=cols_equi, cols_drop=cols_drop)\n",
    "x_train.shape, y_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대중소세 코드 값 가지고 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D : 대-중-소-세-d 일치여부 score\n",
    "x_train['person_D_code1_score'] = (x_train['d_l_match_yn'] + x_train['person_prefer_d_1_attribute_d_m_contents_attribute_d_attribute_d_m'] \\\n",
    "                                + x_train['person_prefer_d_1_attribute_d_s_contents_attribute_d_attribute_d_s'] + x_train['d_m_match_yn'] + x_train['d_s_match_yn'])\n",
    "x_train['person_D_code2_score'] = (x_train['person_prefer_d_2_attribute_d_l_contents_attribute_d_attribute_d_l'] + x_train['person_prefer_d_2_attribute_d_m_contents_attribute_d_attribute_d_m'] \\\n",
    "                                + x_train['person_prefer_d_2_attribute_d_s_contents_attribute_d_attribute_d_s'] + x_train['person_prefer_d_2_attribute_d_d_contents_attribute_d_attribute_d_d']\\\n",
    "                                + x_train['person_prefer_d_2_contents_attribute_d'])\n",
    "x_train['person_D_code3_score'] = (x_train['person_prefer_d_3_attribute_d_l_contents_attribute_d_attribute_d_l'] + x_train['person_prefer_d_3_attribute_d_m_contents_attribute_d_attribute_d_m'] \\\n",
    "                                + x_train['person_prefer_d_3_attribute_d_s_contents_attribute_d_attribute_d_s'] + x_train['person_prefer_d_3_attribute_d_d_contents_attribute_d_attribute_d_d']\\\n",
    "                                + x_train['person_prefer_d_3_contents_attribute_d'])\n",
    "\n",
    "x_test['person_D_code1_score'] =( x_test['d_l_match_yn'] + x_test['person_prefer_d_1_attribute_d_m_contents_attribute_d_attribute_d_m'] \\\n",
    "                                + x_test['person_prefer_d_1_attribute_d_s_contents_attribute_d_attribute_d_s'] + x_test['d_m_match_yn'] + x_test['d_s_match_yn'])\n",
    "x_test['person_D_code2_score'] = (x_test['person_prefer_d_2_attribute_d_l_contents_attribute_d_attribute_d_l'] + x_test['person_prefer_d_2_attribute_d_m_contents_attribute_d_attribute_d_m'] \\\n",
    "                                + x_test['person_prefer_d_2_attribute_d_s_contents_attribute_d_attribute_d_s'] + x_test['person_prefer_d_2_attribute_d_d_contents_attribute_d_attribute_d_d']\\\n",
    "                                + x_test['person_prefer_d_2_contents_attribute_d'])\n",
    "x_test['person_D_code3_score'] = (x_test['person_prefer_d_3_attribute_d_l_contents_attribute_d_attribute_d_l'] + x_test['person_prefer_d_3_attribute_d_m_contents_attribute_d_attribute_d_m'] \\\n",
    "                                + x_test['person_prefer_d_3_attribute_d_s_contents_attribute_d_attribute_d_s'] + x_test['person_prefer_d_3_attribute_d_d_contents_attribute_d_attribute_d_d']\\\n",
    "                                + x_test['person_prefer_d_3_contents_attribute_d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H : 대-중-d 일치여부 score\n",
    "x_train['person_H_code1_score'] = (x_train['h_l_match_yn'] + x_train['h_m_match_yn'] + x_train['h_s_match_yn'])\n",
    "x_train['person_H_code2_score'] = (x_train['person_prefer_h_2_attribute_h_l_contents_attribute_h_attribute_h_l'] + x_train['person_prefer_h_2_attribute_h_m_contents_attribute_h_attribute_h_m']\\\n",
    "                                 + x_train['person_prefer_h_2_contents_attribute_h'])\n",
    "x_train['person_H_code3_score'] = (x_train['person_prefer_h_3_attribute_h_l_contents_attribute_h_attribute_h_l'] + x_train['person_prefer_h_3_attribute_h_m_contents_attribute_h_attribute_h_m']\\\n",
    "                                 + x_train['person_prefer_h_3_contents_attribute_h'])\n",
    "\n",
    "x_test['person_H_code1_score'] = (x_test['h_l_match_yn'] + x_test['h_m_match_yn']  + x_test['h_s_match_yn'])\n",
    "x_test['person_H_code2_score'] = (x_test['person_prefer_h_2_attribute_h_l_contents_attribute_h_attribute_h_l'] + x_test['person_prefer_h_2_attribute_h_m_contents_attribute_h_attribute_h_m']\\\n",
    "                                 + x_test['person_prefer_h_2_contents_attribute_h'])\n",
    "x_test['person_H_code3_score'] = (x_test['person_prefer_h_3_attribute_h_l_contents_attribute_h_attribute_h_l'] + x_test['person_prefer_h_3_attribute_h_m_contents_attribute_h_attribute_h_m']\\\n",
    "                                 + x_test['person_prefer_h_3_contents_attribute_h'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['content_L_code_sum'] = x_train['contents_attribute_l_attribute_l_l'] + x_train['contents_attribute_l_attribute_l_m'] \\\n",
    "                                + x_train['contents_attribute_l_attribute_l_s'] + x_train['contents_attribute_l_attribute_l_d']\n",
    "\n",
    "x_test['content_L_code_sum'] = x_test['contents_attribute_l_attribute_l_l'] + x_test['contents_attribute_l_attribute_l_m'] \\\n",
    "                               + x_test['contents_attribute_l_attribute_l_s'] + x_test['contents_attribute_l_attribute_l_d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['D_H_1_mul'] = x_train['person_D_code1_score'] * x_train['person_H_code1_score']\n",
    "x_train['D_H_2_mul'] = x_train['person_D_code2_score'] * x_train['person_H_code2_score']\n",
    "x_train['D_H_3_mul'] = x_train['person_D_code3_score'] * x_train['person_H_code3_score']\n",
    "x_train['D_H_1_sum'] = x_train['person_D_code1_score'] + x_train['person_H_code1_score']\n",
    "x_train['D_H_2_sum'] = x_train['person_D_code2_score'] + x_train['person_H_code2_score']\n",
    "x_train['D_H_3_sum'] = x_train['person_D_code3_score'] + x_train['person_H_code3_score']\n",
    "\n",
    "x_test['D_H_1_mul'] = x_test['person_D_code1_score'] * x_test['person_H_code1_score']\n",
    "x_test['D_H_2_mul'] = x_test['person_D_code2_score'] * x_test['person_H_code2_score']\n",
    "x_test['D_H_3_mul'] = x_test['person_D_code3_score'] * x_test['person_H_code3_score']\n",
    "x_test['D_H_1_sum'] = x_test['person_D_code1_score'] + x_test['person_H_code1_score']\n",
    "x_test['D_H_2_sum'] = x_test['person_D_code2_score'] + x_test['person_H_code2_score']\n",
    "x_test['D_H_3_sum'] = x_test['person_D_code3_score'] + x_test['person_H_code3_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['DD_12_diff'] = x_train['person_D_code1_score'] - x_train['person_D_code2_score']\n",
    "x_train['DD_13_diff'] = x_train['person_D_code1_score'] - x_train['person_D_code3_score']\n",
    "x_train['DD_23_diff'] = x_train['person_D_code2_score'] - x_train['person_D_code3_score']\n",
    "\n",
    "x_test['DD_12_diff'] = x_test['person_D_code1_score'] - x_test['person_D_code2_score']\n",
    "x_test['DD_13_diff'] = x_test['person_D_code1_score'] - x_test['person_D_code3_score']\n",
    "x_test['DD_23_diff'] = x_test['person_D_code2_score'] - x_test['person_D_code3_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['HH_12_diff'] = x_train['person_H_code1_score'] - x_train['person_H_code2_score']\n",
    "x_train['HH_13_diff'] = x_train['person_H_code1_score'] - x_train['person_H_code3_score']\n",
    "x_train['HH_23_diff'] = x_train['person_H_code2_score'] - x_train['person_H_code3_score']\n",
    "\n",
    "x_test['HH_12_diff'] = x_test['person_H_code1_score'] - x_test['person_H_code2_score']\n",
    "x_test['HH_13_diff'] = x_test['person_H_code1_score'] - x_test['person_H_code3_score']\n",
    "x_test['HH_23_diff'] = x_test['person_H_code2_score'] - x_test['person_H_code3_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['DDD_sum'] = x_train['person_D_code1_score'] + x_train['person_D_code2_score'] + x_train['person_D_code3_score']\n",
    "x_train['HHH_sum'] = x_train['person_H_code1_score'] + x_train['person_H_code2_score'] + x_train['person_H_code3_score']\n",
    "\n",
    "x_test['DDD_sum'] = x_test['person_D_code1_score'] + x_test['person_D_code2_score'] + x_test['person_D_code3_score']\n",
    "x_test['HHH_sum'] = x_test['person_H_code1_score'] + x_test['person_H_code2_score'] + x_test['person_H_code3_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['person_contents_e_diff'] = x_train['person_prefer_e'] - x_train['contents_attribute_e']\n",
    "x_test['person_contents_e_diff'] = x_test['person_prefer_e'] - x_test['contents_attribute_e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['D_E_1_mul'] = x_train['person_D_code1_score'] * x_train['person_contents_e_diff']\n",
    "x_train['D_E_2_mul'] = x_train['person_D_code2_score'] * x_train['person_contents_e_diff']\n",
    "x_train['D_E_3_mul'] = x_train['person_D_code3_score'] * x_train['person_contents_e_diff']\n",
    "x_train['D_E_1_sum'] = x_train['person_D_code1_score'] + x_train['person_contents_e_diff']\n",
    "x_train['D_E_2_sum'] = x_train['person_D_code2_score'] + x_train['person_contents_e_diff']\n",
    "x_train['D_E_3_sum'] = x_train['person_D_code3_score'] + x_train['person_contents_e_diff']\n",
    "\n",
    "x_test['D_E_1_mul'] = x_test['person_D_code1_score'] * x_test['person_contents_e_diff']\n",
    "x_test['D_E_2_mul'] = x_test['person_D_code2_score'] * x_test['person_contents_e_diff']\n",
    "x_test['D_E_3_mul'] = x_test['person_D_code3_score'] * x_test['person_contents_e_diff']\n",
    "x_test['D_E_1_sum'] = x_test['person_D_code1_score'] + x_test['person_contents_e_diff']\n",
    "x_test['D_E_2_sum'] = x_test['person_D_code2_score'] + x_test['person_contents_e_diff']\n",
    "x_test['D_E_3_sum'] = x_test['person_D_code3_score'] + x_test['person_contents_e_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['H_E_1_mul'] = x_train['person_H_code1_score'] * x_train['person_contents_e_diff']\n",
    "x_train['H_E_2_mul'] = x_train['person_H_code2_score'] * x_train['person_contents_e_diff']\n",
    "x_train['H_E_3_mul'] = x_train['person_H_code3_score'] * x_train['person_contents_e_diff']\n",
    "x_train['H_E_1_sum'] = x_train['person_H_code1_score'] + x_train['person_contents_e_diff']\n",
    "x_train['H_E_2_sum'] = x_train['person_H_code2_score'] + x_train['person_contents_e_diff']\n",
    "x_train['H_E_3_sum'] = x_train['person_H_code3_score'] + x_train['person_contents_e_diff']\n",
    "\n",
    "x_test['H_E_1_mul'] = x_test['person_H_code1_score'] * x_test['person_contents_e_diff']\n",
    "x_test['H_E_2_mul'] = x_test['person_H_code2_score'] * x_test['person_contents_e_diff']\n",
    "x_test['H_E_3_mul'] = x_test['person_H_code3_score'] * x_test['person_contents_e_diff']\n",
    "x_test['H_E_1_sum'] = x_test['person_H_code1_score'] + x_test['person_contents_e_diff']\n",
    "x_test['H_E_2_sum'] = x_test['person_H_code2_score'] + x_test['person_contents_e_diff']\n",
    "x_test['H_E_3_sum'] = x_test['person_H_code3_score'] + x_test['person_contents_e_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['L_E_mul'] = x_train['content_L_code_sum'] * x_train['person_contents_e_diff']\n",
    "x_train['L_E_sum'] = x_train['content_L_code_sum'] + x_train['person_contents_e_diff']\n",
    "\n",
    "x_test['L_E_mul'] = x_test['content_L_code_sum'] * x_test['person_contents_e_diff']\n",
    "x_test['L_E_sum'] = x_test['content_L_code_sum'] + x_test['person_contents_e_diff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### J assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([x_train, train.target],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a= pd.pivot_table(data, values='target',index='contents_attribute_j',\n",
    "    columns='contents_attribute_j_1',\n",
    "    aggfunc='sum', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= pd.pivot_table(data, values='target',index='contents_attribute_j',\n",
    "    columns='contents_attribute_j_1',\n",
    "    aggfunc='count', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>contents_attribute_j_1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contents_attribute_j</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.093927</td>\n",
       "      <td>0.32543</td>\n",
       "      <td>0.530409</td>\n",
       "      <td>0.527519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.487139</td>\n",
       "      <td>0.437956</td>\n",
       "      <td>0.431964</td>\n",
       "      <td>0.472427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "contents_attribute_j_1        1         2        3         4         5   \\\n",
       "contents_attribute_j                                                      \n",
       "1                       0.615385  0.093927  0.32543  0.530409  0.527519   \n",
       "2                            NaN       NaN      NaN       NaN       NaN   \n",
       "\n",
       "contents_attribute_j_1        6         8         9         10  \n",
       "contents_attribute_j                                            \n",
       "1                            NaN       NaN       NaN       NaN  \n",
       "2                       0.487139  0.437956  0.431964  0.472427  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['j_assemble']=x_train['contents_attribute_j'] * x_train['contents_attribute_j_1']\n",
    "x_test['j_assemble']=x_test['contents_attribute_j'] * x_test['contents_attribute_j_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['a_assemble']=x_train['person_attribute_a'].astype(str) + '_' + x_train['contents_attribute_a'].astype(str)\n",
    "x_test['a_assemble']=x_test['person_attribute_a'].astype(str) + '_' + x_test['contents_attribute_a'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D assemble\n",
    "- contents_d 와 person_d의 관계를 보기 위해 pivot_table을 이용하여 target encoding을 만듦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D_1_L assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a= pd.pivot_table(data, values='target',index='person_prefer_d_1_attribute_d_l',\n",
    "    columns='contents_attribute_d_attribute_d_l',\n",
    "    aggfunc='sum', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= pd.pivot_table(data, values='target',index='person_prefer_d_1_attribute_d_l',\n",
    "    columns='contents_attribute_d_attribute_d_l',\n",
    "    aggfunc='count', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>contents_attribute_d_attribute_d_l</th>\n",
       "      <th>1</th>\n",
       "      <th>216</th>\n",
       "      <th>377</th>\n",
       "      <th>482</th>\n",
       "      <th>522</th>\n",
       "      <th>618</th>\n",
       "      <th>744</th>\n",
       "      <th>864</th>\n",
       "      <th>926</th>\n",
       "      <th>1235</th>\n",
       "      <th>1258</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_prefer_d_1_attribute_d_l</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.577416</td>\n",
       "      <td>0.348087</td>\n",
       "      <td>0.292436</td>\n",
       "      <td>0.275927</td>\n",
       "      <td>0.326954</td>\n",
       "      <td>0.283027</td>\n",
       "      <td>0.431737</td>\n",
       "      <td>0.313196</td>\n",
       "      <td>0.372367</td>\n",
       "      <td>0.170455</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.524900</td>\n",
       "      <td>0.598649</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.505848</td>\n",
       "      <td>0.379648</td>\n",
       "      <td>0.394518</td>\n",
       "      <td>0.465668</td>\n",
       "      <td>0.472571</td>\n",
       "      <td>0.273810</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.501129</td>\n",
       "      <td>0.286765</td>\n",
       "      <td>0.505151</td>\n",
       "      <td>0.307004</td>\n",
       "      <td>0.415954</td>\n",
       "      <td>0.330265</td>\n",
       "      <td>0.383857</td>\n",
       "      <td>0.246269</td>\n",
       "      <td>0.347168</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0.487420</td>\n",
       "      <td>0.291429</td>\n",
       "      <td>0.293035</td>\n",
       "      <td>0.625022</td>\n",
       "      <td>0.239437</td>\n",
       "      <td>0.323583</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.332207</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>0.560093</td>\n",
       "      <td>0.493617</td>\n",
       "      <td>0.338290</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.660348</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>0.556684</td>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.476839</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>0.498507</td>\n",
       "      <td>0.362729</td>\n",
       "      <td>0.315197</td>\n",
       "      <td>0.349638</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.579576</td>\n",
       "      <td>0.470266</td>\n",
       "      <td>0.440068</td>\n",
       "      <td>0.467452</td>\n",
       "      <td>0.373239</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>0.527941</td>\n",
       "      <td>0.353226</td>\n",
       "      <td>0.241960</td>\n",
       "      <td>0.292419</td>\n",
       "      <td>0.364179</td>\n",
       "      <td>0.431117</td>\n",
       "      <td>0.560200</td>\n",
       "      <td>0.431910</td>\n",
       "      <td>0.444589</td>\n",
       "      <td>0.393782</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0.476625</td>\n",
       "      <td>0.487385</td>\n",
       "      <td>0.277108</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.408696</td>\n",
       "      <td>0.517885</td>\n",
       "      <td>0.589229</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.388060</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>0.420474</td>\n",
       "      <td>0.396458</td>\n",
       "      <td>0.183044</td>\n",
       "      <td>0.215447</td>\n",
       "      <td>0.247984</td>\n",
       "      <td>0.345951</td>\n",
       "      <td>0.406093</td>\n",
       "      <td>0.414907</td>\n",
       "      <td>0.502301</td>\n",
       "      <td>0.280255</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>0.537815</td>\n",
       "      <td>0.582278</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.603960</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.507317</td>\n",
       "      <td>0.564444</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "contents_attribute_d_attribute_d_l      1         216       377       482   \\\n",
       "person_prefer_d_1_attribute_d_l                                              \n",
       "1                                   0.577416  0.348087  0.292436  0.275927   \n",
       "216                                 0.524900  0.598649  0.259259  0.321429   \n",
       "377                                 0.501129  0.286765  0.505151  0.307004   \n",
       "482                                 0.487420  0.291429  0.293035  0.625022   \n",
       "522                                 0.560093  0.493617  0.338290  0.255814   \n",
       "618                                 0.498507  0.362729  0.315197  0.349638   \n",
       "744                                 0.527941  0.353226  0.241960  0.292419   \n",
       "864                                 0.476625  0.487385  0.277108  0.263158   \n",
       "926                                 0.420474  0.396458  0.183044  0.215447   \n",
       "1235                                0.537815  0.582278  0.307692  0.000000   \n",
       "1258                                0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "contents_attribute_d_attribute_d_l      522       618       744       864   \\\n",
       "person_prefer_d_1_attribute_d_l                                              \n",
       "1                                   0.326954  0.283027  0.431737  0.313196   \n",
       "216                                 0.505848  0.379648  0.394518  0.465668   \n",
       "377                                 0.415954  0.330265  0.383857  0.246269   \n",
       "482                                 0.239437  0.323583  0.342105  0.196429   \n",
       "522                                 0.660348  0.415686  0.556684  0.430233   \n",
       "618                                 0.319444  0.579576  0.470266  0.440068   \n",
       "744                                 0.364179  0.431117  0.560200  0.431910   \n",
       "864                                 0.571429  0.408696  0.517885  0.589229   \n",
       "926                                 0.247984  0.345951  0.406093  0.414907   \n",
       "1235                                0.285714  0.603960  0.520833  0.611111   \n",
       "1258                                0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "contents_attribute_d_attribute_d_l      926       1235  1258  \n",
       "person_prefer_d_1_attribute_d_l                               \n",
       "1                                   0.372367  0.170455  0.25  \n",
       "216                                 0.472571  0.273810  0.00  \n",
       "377                                 0.347168  0.089286  0.00  \n",
       "482                                 0.332207  0.172414  0.00  \n",
       "522                                 0.476839  0.333333  0.00  \n",
       "618                                 0.467452  0.373239  0.00  \n",
       "744                                 0.444589  0.393782  0.00  \n",
       "864                                 0.501591  0.388060  0.00  \n",
       "926                                 0.502301  0.280255  0.00  \n",
       "1235                                0.507317  0.564444  0.00  \n",
       "1258                                1.000000  0.000000  0.00  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab=(a/b).fillna(0)\n",
    "ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_1_l_target = []\n",
    "for i in range(11):\n",
    "    d_1_l_target.append(list(ab.iloc[i,:] + ab.iloc[:,i]))\n",
    "d_1_l_target= pd.DataFrame(d_1_l_target, columns=list(ab.columns))\n",
    "d_1_l_target.index = list(ab.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['d_1_l_target']=0\n",
    "x_test['d_1_l_target']=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D_2_L assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a= pd.pivot_table(data, values='target',index='person_prefer_d_2_attribute_d_l',\n",
    "    columns='contents_attribute_d_attribute_d_l',\n",
    "    aggfunc='sum', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= pd.pivot_table(data, values='target',index='person_prefer_d_2_attribute_d_l',\n",
    "    columns='contents_attribute_d_attribute_d_l',\n",
    "    aggfunc='count', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>contents_attribute_d_attribute_d_l</th>\n",
       "      <th>1</th>\n",
       "      <th>216</th>\n",
       "      <th>377</th>\n",
       "      <th>482</th>\n",
       "      <th>522</th>\n",
       "      <th>618</th>\n",
       "      <th>744</th>\n",
       "      <th>864</th>\n",
       "      <th>926</th>\n",
       "      <th>1235</th>\n",
       "      <th>1258</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_prefer_d_2_attribute_d_l</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.576027</td>\n",
       "      <td>0.396947</td>\n",
       "      <td>0.332855</td>\n",
       "      <td>0.372775</td>\n",
       "      <td>0.348470</td>\n",
       "      <td>0.279459</td>\n",
       "      <td>0.450208</td>\n",
       "      <td>0.297393</td>\n",
       "      <td>0.373357</td>\n",
       "      <td>0.180828</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.534165</td>\n",
       "      <td>0.610883</td>\n",
       "      <td>0.248031</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.579869</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.403592</td>\n",
       "      <td>0.485549</td>\n",
       "      <td>0.472514</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.519663</td>\n",
       "      <td>0.291284</td>\n",
       "      <td>0.491415</td>\n",
       "      <td>0.578765</td>\n",
       "      <td>0.373377</td>\n",
       "      <td>0.296623</td>\n",
       "      <td>0.384468</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.332158</td>\n",
       "      <td>0.160714</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0.493294</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>0.470320</td>\n",
       "      <td>0.587237</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.340094</td>\n",
       "      <td>0.385852</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.364078</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>0.563205</td>\n",
       "      <td>0.447115</td>\n",
       "      <td>0.393130</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.671146</td>\n",
       "      <td>0.453744</td>\n",
       "      <td>0.558659</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.456716</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>0.505607</td>\n",
       "      <td>0.360759</td>\n",
       "      <td>0.350323</td>\n",
       "      <td>0.421795</td>\n",
       "      <td>0.330677</td>\n",
       "      <td>0.568209</td>\n",
       "      <td>0.479619</td>\n",
       "      <td>0.501027</td>\n",
       "      <td>0.477540</td>\n",
       "      <td>0.331288</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>0.518487</td>\n",
       "      <td>0.356498</td>\n",
       "      <td>0.282209</td>\n",
       "      <td>0.352239</td>\n",
       "      <td>0.377309</td>\n",
       "      <td>0.460793</td>\n",
       "      <td>0.548083</td>\n",
       "      <td>0.512167</td>\n",
       "      <td>0.447857</td>\n",
       "      <td>0.387850</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0.514042</td>\n",
       "      <td>0.492147</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.513060</td>\n",
       "      <td>0.505654</td>\n",
       "      <td>0.581687</td>\n",
       "      <td>0.518349</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>0.450721</td>\n",
       "      <td>0.426480</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.246454</td>\n",
       "      <td>0.256881</td>\n",
       "      <td>0.359005</td>\n",
       "      <td>0.416403</td>\n",
       "      <td>0.422455</td>\n",
       "      <td>0.501685</td>\n",
       "      <td>0.281188</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.579439</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.438298</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "contents_attribute_d_attribute_d_l      1         216       377       482   \\\n",
       "person_prefer_d_2_attribute_d_l                                              \n",
       "1                                   0.576027  0.396947  0.332855  0.372775   \n",
       "216                                 0.534165  0.610883  0.248031  0.320000   \n",
       "377                                 0.519663  0.291284  0.491415  0.578765   \n",
       "482                                 0.493294  0.330769  0.470320  0.587237   \n",
       "522                                 0.563205  0.447115  0.393130  0.392157   \n",
       "618                                 0.505607  0.360759  0.350323  0.421795   \n",
       "744                                 0.518487  0.356498  0.282209  0.352239   \n",
       "864                                 0.514042  0.492147  0.327869  0.225806   \n",
       "926                                 0.450721  0.426480  0.212121  0.246454   \n",
       "1235                                0.487179  0.579439  0.275862  0.000000   \n",
       "1258                                0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "contents_attribute_d_attribute_d_l      522       618       744       864   \\\n",
       "person_prefer_d_2_attribute_d_l                                              \n",
       "1                                   0.348470  0.279459  0.450208  0.297393   \n",
       "216                                 0.579869  0.396226  0.403592  0.485549   \n",
       "377                                 0.373377  0.296623  0.384468  0.245614   \n",
       "482                                 0.297872  0.340094  0.385852  0.153846   \n",
       "522                                 0.671146  0.453744  0.558659  0.500000   \n",
       "618                                 0.330677  0.568209  0.479619  0.501027   \n",
       "744                                 0.377309  0.460793  0.548083  0.512167   \n",
       "864                                 0.588235  0.513060  0.505654  0.581687   \n",
       "926                                 0.256881  0.359005  0.416403  0.422455   \n",
       "1235                                0.333333  0.565217  0.495726  0.530612   \n",
       "1258                                0.000000  1.000000  0.000000  0.000000   \n",
       "\n",
       "contents_attribute_d_attribute_d_l      926       1235      1258  \n",
       "person_prefer_d_2_attribute_d_l                                   \n",
       "1                                   0.373357  0.180828  0.333333  \n",
       "216                                 0.472514  0.229167  0.000000  \n",
       "377                                 0.332158  0.160714  0.000000  \n",
       "482                                 0.364078  0.222222  0.000000  \n",
       "522                                 0.456716  0.333333  0.000000  \n",
       "618                                 0.477540  0.331288  0.000000  \n",
       "744                                 0.447857  0.387850  0.000000  \n",
       "864                                 0.518349  0.436364  0.000000  \n",
       "926                                 0.501685  0.281188  0.000000  \n",
       "1235                                0.438298  0.592593  0.000000  \n",
       "1258                                1.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab=(a/b).fillna(0)\n",
    "ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_2_l_target = []\n",
    "for i in range(11):\n",
    "    d_2_l_target.append(list(ab.iloc[i,:] + ab.iloc[:,i]))\n",
    "d_2_l_target= pd.DataFrame(d_2_l_target, columns=list(ab.columns))\n",
    "d_2_l_target.index = list(ab.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['d_2_l_target']=0\n",
    "x_test['d_2_l_target']=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D_3_L assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a= pd.pivot_table(data, values='target',index='person_prefer_d_3_attribute_d_l',\n",
    "    columns='contents_attribute_d_attribute_d_l',\n",
    "    aggfunc='sum', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= pd.pivot_table(data, values='target',index='person_prefer_d_3_attribute_d_l',\n",
    "    columns='contents_attribute_d_attribute_d_l',\n",
    "    aggfunc='count', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>contents_attribute_d_attribute_d_l</th>\n",
       "      <th>1</th>\n",
       "      <th>216</th>\n",
       "      <th>377</th>\n",
       "      <th>482</th>\n",
       "      <th>522</th>\n",
       "      <th>618</th>\n",
       "      <th>744</th>\n",
       "      <th>864</th>\n",
       "      <th>926</th>\n",
       "      <th>1235</th>\n",
       "      <th>1258</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_prefer_d_3_attribute_d_l</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.573550</td>\n",
       "      <td>0.448115</td>\n",
       "      <td>0.408043</td>\n",
       "      <td>0.500075</td>\n",
       "      <td>0.329302</td>\n",
       "      <td>0.301267</td>\n",
       "      <td>0.436716</td>\n",
       "      <td>0.330151</td>\n",
       "      <td>0.371168</td>\n",
       "      <td>0.177515</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.540398</td>\n",
       "      <td>0.580759</td>\n",
       "      <td>0.311321</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.618221</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.455128</td>\n",
       "      <td>0.491622</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.534091</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.487160</td>\n",
       "      <td>0.421739</td>\n",
       "      <td>0.531599</td>\n",
       "      <td>0.316505</td>\n",
       "      <td>0.420891</td>\n",
       "      <td>0.263736</td>\n",
       "      <td>0.380074</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.349570</td>\n",
       "      <td>0.603416</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.439141</td>\n",
       "      <td>0.394495</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.409884</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>0.553817</td>\n",
       "      <td>0.477089</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.658374</td>\n",
       "      <td>0.414747</td>\n",
       "      <td>0.563327</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.463566</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>0.504097</td>\n",
       "      <td>0.372781</td>\n",
       "      <td>0.338006</td>\n",
       "      <td>0.359055</td>\n",
       "      <td>0.318408</td>\n",
       "      <td>0.560235</td>\n",
       "      <td>0.501558</td>\n",
       "      <td>0.485666</td>\n",
       "      <td>0.485141</td>\n",
       "      <td>0.371069</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>0.501820</td>\n",
       "      <td>0.348794</td>\n",
       "      <td>0.272066</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.369021</td>\n",
       "      <td>0.500905</td>\n",
       "      <td>0.537848</td>\n",
       "      <td>0.446735</td>\n",
       "      <td>0.480244</td>\n",
       "      <td>0.341137</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0.478873</td>\n",
       "      <td>0.607190</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.464720</td>\n",
       "      <td>0.520570</td>\n",
       "      <td>0.585930</td>\n",
       "      <td>0.515181</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>0.460313</td>\n",
       "      <td>0.437612</td>\n",
       "      <td>0.202077</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.256513</td>\n",
       "      <td>0.357879</td>\n",
       "      <td>0.480250</td>\n",
       "      <td>0.440427</td>\n",
       "      <td>0.498098</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.544643</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.570652</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "contents_attribute_d_attribute_d_l      1         216       377       482   \\\n",
       "person_prefer_d_3_attribute_d_l                                              \n",
       "1                                   0.573550  0.448115  0.408043  0.500075   \n",
       "216                                 0.540398  0.580759  0.311321  0.357143   \n",
       "377                                 0.534091  0.351351  0.487160  0.421739   \n",
       "482                                 0.569832  0.382353  0.349570  0.603416   \n",
       "522                                 0.553817  0.477089  0.357143  0.256410   \n",
       "618                                 0.504097  0.372781  0.338006  0.359055   \n",
       "744                                 0.501820  0.348794  0.272066  0.348837   \n",
       "864                                 0.478873  0.607190  0.375000  0.176471   \n",
       "926                                 0.460313  0.437612  0.202077  0.255814   \n",
       "1235                                0.514706  0.633333  0.346154  0.333333   \n",
       "1258                                0.000000  0.000000  0.000000  1.000000   \n",
       "\n",
       "contents_attribute_d_attribute_d_l      522       618       744       864   \\\n",
       "person_prefer_d_3_attribute_d_l                                              \n",
       "1                                   0.329302  0.301267  0.436716  0.330151   \n",
       "216                                 0.618221  0.353846  0.450980  0.455128   \n",
       "377                                 0.531599  0.316505  0.420891  0.263736   \n",
       "482                                 0.365854  0.439141  0.394495  0.321429   \n",
       "522                                 0.658374  0.414747  0.563327  0.404255   \n",
       "618                                 0.318408  0.560235  0.501558  0.485666   \n",
       "744                                 0.369021  0.500905  0.537848  0.446735   \n",
       "864                                 0.702703  0.464720  0.520570  0.585930   \n",
       "926                                 0.256513  0.357879  0.480250  0.440427   \n",
       "1235                                0.307692  0.590000  0.544643  0.461538   \n",
       "1258                                0.000000  0.666667  0.000000  0.000000   \n",
       "\n",
       "contents_attribute_d_attribute_d_l      926       1235      1258  \n",
       "person_prefer_d_3_attribute_d_l                                   \n",
       "1                                   0.371168  0.177515  0.333333  \n",
       "216                                 0.491622  0.214286  0.000000  \n",
       "377                                 0.380074  0.250000  0.000000  \n",
       "482                                 0.409884  0.142857  0.000000  \n",
       "522                                 0.463566  0.333333  0.000000  \n",
       "618                                 0.485141  0.371069  0.000000  \n",
       "744                                 0.480244  0.341137  0.000000  \n",
       "864                                 0.515181  0.375000  0.000000  \n",
       "926                                 0.498098  0.301887  0.000000  \n",
       "1235                                0.500000  0.570652  0.000000  \n",
       "1258                                1.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab=(a/b).fillna(0)\n",
    "ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_3_l_target = []\n",
    "for i in range(11):\n",
    "    d_3_l_target.append(list(ab.iloc[i,:] + ab.iloc[:,i]))\n",
    "d_3_l_target= pd.DataFrame(d_3_l_target, columns=list(ab.columns))\n",
    "d_3_l_target.index = list(ab.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['d_3_l_target']=0\n",
    "x_test['d_3_l_target']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(x_train.shape[0])):\n",
    "    x_train.loc[i,'d_1_l_target'] = d_1_l_target.loc[x_train.person_prefer_d_1_attribute_d_l[i],x_train.contents_attribute_d_attribute_d_l[i]]\n",
    "    x_train.loc[i,'d_2_l_target'] = d_2_l_target.loc[x_train.person_prefer_d_2_attribute_d_l[i],x_train.contents_attribute_d_attribute_d_l[i]]\n",
    "    x_train.loc[i,'d_3_l_target'] = d_3_l_target.loc[x_train.person_prefer_d_3_attribute_d_l[i],x_train.contents_attribute_d_attribute_d_l[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(x_test.shape[0])):\n",
    "    x_test.loc[i,'d_1_l_target'] = d_1_l_target.loc[x_test.person_prefer_d_1_attribute_d_l[i],x_test.contents_attribute_d_attribute_d_l[i]]\n",
    "    x_test.loc[i,'d_2_l_target'] = d_2_l_target.loc[x_test.person_prefer_d_2_attribute_d_l[i],x_test.contents_attribute_d_attribute_d_l[i]]\n",
    "    x_test.loc[i,'d_3_l_target'] = d_3_l_target.loc[x_test.person_prefer_d_3_attribute_d_l[i],x_test.contents_attribute_d_attribute_d_l[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.iloc[:,:-3]\n",
    "x_test = x_test.iloc[:,:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((501951, 118), (46404, 118))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HH_23_diff</th>\n",
       "      <th>DDD_sum</th>\n",
       "      <th>HHH_sum</th>\n",
       "      <th>person_contents_e_diff</th>\n",
       "      <th>D_E_1_mul</th>\n",
       "      <th>D_E_2_mul</th>\n",
       "      <th>D_E_3_mul</th>\n",
       "      <th>D_E_1_sum</th>\n",
       "      <th>D_E_2_sum</th>\n",
       "      <th>D_E_3_sum</th>\n",
       "      <th>H_E_1_mul</th>\n",
       "      <th>H_E_2_mul</th>\n",
       "      <th>H_E_3_mul</th>\n",
       "      <th>H_E_1_sum</th>\n",
       "      <th>H_E_2_sum</th>\n",
       "      <th>H_E_3_sum</th>\n",
       "      <th>L_E_mul</th>\n",
       "      <th>L_E_sum</th>\n",
       "      <th>j_assemble</th>\n",
       "      <th>a_assemble</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>27336</td>\n",
       "      <td>6838</td>\n",
       "      <td>20</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6834</td>\n",
       "      <td>5</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-6782</td>\n",
       "      <td>6781</td>\n",
       "      <td>20</td>\n",
       "      <td>2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6834</td>\n",
       "      <td>5</td>\n",
       "      <td>2_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6834</td>\n",
       "      <td>20</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501946</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-6102</td>\n",
       "      <td>3049</td>\n",
       "      <td>5</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501947</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2398</td>\n",
       "      <td>20</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501948</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-15</td>\n",
       "      <td>-3</td>\n",
       "      <td>-12</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-9801</td>\n",
       "      <td>3264</td>\n",
       "      <td>5</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501949</th>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3968</td>\n",
       "      <td>5</td>\n",
       "      <td>1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501950</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4334</td>\n",
       "      <td>4335</td>\n",
       "      <td>5</td>\n",
       "      <td>1_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501951 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        HH_23_diff  DDD_sum  HHH_sum  person_contents_e_diff  D_E_1_mul  \\\n",
       "0                1        7        1                       4         20   \n",
       "1                0        0        4                       0          0   \n",
       "2               -1        2        2                      -1          0   \n",
       "3                0        0        1                       0          0   \n",
       "4                0        7        0                       0          0   \n",
       "...            ...      ...      ...                     ...        ...   \n",
       "501946           0        0        1                      -2          0   \n",
       "501947           2       10        5                       0          0   \n",
       "501948           0       10        1                      -3        -15   \n",
       "501949          -1       10        2                       0          0   \n",
       "501950           0       10        1                       1          5   \n",
       "\n",
       "        D_E_2_mul  D_E_3_mul  D_E_1_sum  D_E_2_sum  D_E_3_sum  H_E_1_mul  \\\n",
       "0               4          4          9          5          5          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2              -2          0         -1          1         -1         -1   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          5          1          1          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "501946          0          0         -2         -2         -2         -2   \n",
       "501947          0          0          4          3          3          0   \n",
       "501948         -3        -12          2         -2          1         -3   \n",
       "501949          0          0          1          5          4          0   \n",
       "501950          1          4          6          2          5          1   \n",
       "\n",
       "        H_E_2_mul  H_E_3_mul  H_E_1_sum  H_E_2_sum  H_E_3_sum  L_E_mul  \\\n",
       "0               4          0          4          5          4    27336   \n",
       "1               0          0          2          1          1        0   \n",
       "2               0         -1          0         -1          0    -6782   \n",
       "3               0          0          1          0          0        0   \n",
       "4               0          0          0          0          0        0   \n",
       "...           ...        ...        ...        ...        ...      ...   \n",
       "501946          0          0         -1         -2         -2    -6102   \n",
       "501947          0          0          1          3          1        0   \n",
       "501948          0          0         -2         -3         -3    -9801   \n",
       "501949          0          0          1          0          1        0   \n",
       "501950          0          0          2          1          1     4334   \n",
       "\n",
       "        L_E_sum  j_assemble a_assemble  \n",
       "0          6838          20        1_3  \n",
       "1          6834           5        1_3  \n",
       "2          6781          20        2_1  \n",
       "3          6834           5        2_3  \n",
       "4          6834          20        1_1  \n",
       "...         ...         ...        ...  \n",
       "501946     3049           5        1_3  \n",
       "501947     2398          20        1_3  \n",
       "501948     3264           5        1_1  \n",
       "501949     3968           5        1_2  \n",
       "501950     4335           5        1_3  \n",
       "\n",
       "[501951 rows x 20 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.iloc[:, -20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr= pd.read_csv('x_new.csv')\n",
    "x_te = pd.read_csv('x_te_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['cluster'] = x_tr['cluster']\n",
    "x_test['cluster'] = x_te['cluster']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범주형 칼럼 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['content_L_code_sum','L_E_mul', 'L_E_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_features =['d_1_l_target','d_2_l_target','d_3_l_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = x_train.columns[x_train.nunique() > 2].tolist()\n",
    "cat_features = list(set(cat_features) - set(num_features) - set(target_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가우스-랭크 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.special import erf, erfinv\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import FLOAT_DTYPES, check_array, check_is_fitted\n",
    "\n",
    "class GaussRankScaler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Transform features by scaling each feature to a normal distribution.\n",
    "    Parameters\n",
    "        ----------\n",
    "        epsilon : float, optional, default 1e-4\n",
    "            A small amount added to the lower bound or subtracted\n",
    "            from the upper bound. This value prevents infinite number\n",
    "            from occurring when applying the inverse error function.\n",
    "        copy : boolean, optional, default True\n",
    "            If False, try to avoid a copy and do inplace scaling instead.\n",
    "            This is not guaranteed to always work inplace; e.g. if the data is\n",
    "            not a NumPy array, a copy may still be returned.\n",
    "        n_jobs : int or None, optional, default None\n",
    "            Number of jobs to run in parallel.\n",
    "            ``None`` means 1 and ``-1`` means using all processors.\n",
    "        interp_kind : str or int, optional, default 'linear'\n",
    "           Specifies the kind of interpolation as a string\n",
    "            ('linear', 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
    "            'previous', 'next', where 'zero', 'slinear', 'quadratic' and 'cubic'\n",
    "            refer to a spline interpolation of zeroth, first, second or third\n",
    "            order; 'previous' and 'next' simply return the previous or next value\n",
    "            of the point) or as an integer specifying the order of the spline\n",
    "            interpolator to use.\n",
    "        interp_copy : bool, optional, default False\n",
    "            If True, the interpolation function makes internal copies of x and y.\n",
    "            If False, references to `x` and `y` are used.\n",
    "        Attributes\n",
    "        ----------\n",
    "        interp_func_ : list\n",
    "            The interpolation function for each feature in the training set.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, epsilon=1e-4, copy=True, n_jobs=None, interp_kind='linear', interp_copy=False):\n",
    "        self.epsilon = epsilon\n",
    "        self.copy = copy\n",
    "        self.interp_kind = interp_kind\n",
    "        self.interp_copy = interp_copy\n",
    "        self.fill_value = 'extrapolate'\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit interpolation function to link rank with original data for future scaling\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The data used to fit interpolation function for later scaling along the features axis.\n",
    "        y\n",
    "            Ignored\n",
    "        \"\"\"\n",
    "        X = check_array(X, copy=self.copy, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "\n",
    "        self.interp_func_ = Parallel(n_jobs=self.n_jobs)(delayed(self._fit)(x) for x in X.T)\n",
    "        return self\n",
    "\n",
    "    def _fit(self, x):\n",
    "        x = self.drop_duplicates(x)\n",
    "        rank = np.argsort(np.argsort(x))\n",
    "        bound = 1.0 - self.epsilon\n",
    "        factor = np.max(rank) / 2.0 * bound\n",
    "        scaled_rank = np.clip(rank / factor - bound, -bound, bound)\n",
    "        return interp1d(\n",
    "            x, scaled_rank, kind=self.interp_kind, copy=self.interp_copy, fill_value=self.fill_value)\n",
    "\n",
    "    def transform(self, X, copy=None):\n",
    "        \"\"\"Scale the data with the Gauss Rank algorithm\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The data used to scale along the features axis.\n",
    "        copy : bool, optional (default: None)\n",
    "            Copy the input X or not.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'interp_func_')\n",
    "\n",
    "        copy = copy if copy is not None else self.copy\n",
    "        X = check_array(X, copy=copy, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "\n",
    "        X = np.array(Parallel(n_jobs=self.n_jobs)(delayed(self._transform)(i, x) for i, x in enumerate(X.T))).T\n",
    "        return X\n",
    "\n",
    "    def _transform(self, i, x):\n",
    "        return erfinv(self.interp_func_[i](x))\n",
    "\n",
    "    def inverse_transform(self, X, copy=None):\n",
    "        \"\"\"Scale back the data to the original representation\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_features]\n",
    "            The data used to scale along the features axis.\n",
    "        copy : bool, optional (default: None)\n",
    "            Copy the input X or not.\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, 'interp_func_')\n",
    "\n",
    "        copy = copy if copy is not None else self.copy\n",
    "        X = check_array(X, copy=copy, estimator=self, dtype=FLOAT_DTYPES, force_all_finite=True)\n",
    "\n",
    "        X = np.array(Parallel(n_jobs=self.n_jobs)(delayed(self._inverse_transform)(i, x) for i, x in enumerate(X.T))).T\n",
    "        return X\n",
    "\n",
    "    def _inverse_transform(self, i, x):\n",
    "        inv_interp_func = interp1d(self.interp_func_[i].y, self.interp_func_[i].x, kind=self.interp_kind,\n",
    "                                   copy=self.interp_copy, fill_value=self.fill_value)\n",
    "        return inv_interp_func(erf(x))\n",
    "\n",
    "    @staticmethod\n",
    "    def drop_duplicates(x):\n",
    "        is_unique = np.zeros_like(x, dtype=bool)\n",
    "        is_unique[np.unique(x, return_index=True)[1]] = True\n",
    "        return x[is_unique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GaussRankScaler()\n",
    "x_train[num_features] = pd.DataFrame(scaler.fit_transform(x_train[num_features]))\n",
    "x_test[num_features] = pd.DataFrame(scaler.transform(x_test[num_features]))\n",
    "\n",
    "x_train[num_features].columns = num_features\n",
    "x_test[num_features].columns = num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_L_code_sum</th>\n",
       "      <th>L_E_mul</th>\n",
       "      <th>L_E_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>content_L_code_sum</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014953</td>\n",
       "      <td>0.999693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L_E_mul</th>\n",
       "      <td>-0.014953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L_E_sum</th>\n",
       "      <td>0.999693</td>\n",
       "      <td>-0.012412</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    content_L_code_sum   L_E_mul   L_E_sum\n",
       "content_L_code_sum            1.000000 -0.014953  0.999693\n",
       "L_E_mul                      -0.014953  1.000000 -0.012412\n",
       "L_E_sum                       0.999693 -0.012412  1.000000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[num_features].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['code_match_score'] = train['d_s_match_yn'].astype('int') + train['h_s_match_yn'].astype('int')\n",
    "x_train['l_match_score'] = train['d_l_match_yn'].astype('int') + train['h_l_match_yn'].astype('int')\n",
    "x_train['m_match_score'] = train['d_m_match_yn'].astype('int') + train['h_m_match_yn'].astype('int')\n",
    "\n",
    "x_test['code_match_score'] = test['d_s_match_yn'].astype('int') + test['h_s_match_yn'].astype('int')\n",
    "x_test['l_match_score'] = test['d_l_match_yn'].astype('int') + test['h_l_match_yn'].astype('int')\n",
    "x_test['m_match_score'] = test['d_m_match_yn'].astype('int') + test['h_m_match_yn'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['person_sum_bfg'] = train['person_attribute_b']+train['person_prefer_f']+train['person_prefer_g']\n",
    "x_train['contents_sum_ijkm'] = train['contents_attribute_i']+train['contents_attribute_j']+train['contents_attribute_k']+train['contents_attribute_m']\n",
    "\n",
    "x_test['person_sum_bfg'] = test['person_attribute_b']+test['person_prefer_f']+test['person_prefer_g']\n",
    "x_test['contents_sum_ijkm'] = test['contents_attribute_i']+test['contents_attribute_j']+test['contents_attribute_k']+test['contents_attribute_m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차원축소 및 군집화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = x_train.select_dtypes(include=['object','category']).columns.to_list()\n",
    "num_features = x_train.select_dtypes(exclude=['object','category']).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 118)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_features), len(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501951, 119)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "Learning rate set to 0.146594\n",
      "0:\tlearn: 0.6863681\ttotal: 82.1ms\tremaining: 1m 22s\n",
      "1:\tlearn: 0.6815495\ttotal: 188ms\tremaining: 1m 33s\n",
      "2:\tlearn: 0.6779048\ttotal: 288ms\tremaining: 1m 35s\n",
      "3:\tlearn: 0.6750155\ttotal: 392ms\tremaining: 1m 37s\n",
      "4:\tlearn: 0.6726836\ttotal: 525ms\tremaining: 1m 44s\n",
      "5:\tlearn: 0.6709759\ttotal: 608ms\tremaining: 1m 40s\n",
      "6:\tlearn: 0.6695774\ttotal: 697ms\tremaining: 1m 38s\n",
      "7:\tlearn: 0.6683349\ttotal: 783ms\tremaining: 1m 37s\n",
      "8:\tlearn: 0.6671999\ttotal: 922ms\tremaining: 1m 41s\n",
      "9:\tlearn: 0.6662994\ttotal: 1.02s\tremaining: 1m 41s\n",
      "10:\tlearn: 0.6655176\ttotal: 1.1s\tremaining: 1m 38s\n",
      "11:\tlearn: 0.6646324\ttotal: 1.19s\tremaining: 1m 37s\n",
      "12:\tlearn: 0.6638344\ttotal: 1.29s\tremaining: 1m 37s\n",
      "13:\tlearn: 0.6632044\ttotal: 1.39s\tremaining: 1m 38s\n",
      "14:\tlearn: 0.6626114\ttotal: 1.5s\tremaining: 1m 38s\n",
      "15:\tlearn: 0.6621935\ttotal: 1.58s\tremaining: 1m 36s\n",
      "16:\tlearn: 0.6617031\ttotal: 1.68s\tremaining: 1m 37s\n",
      "17:\tlearn: 0.6610975\ttotal: 1.82s\tremaining: 1m 39s\n",
      "18:\tlearn: 0.6605804\ttotal: 1.9s\tremaining: 1m 38s\n",
      "19:\tlearn: 0.6602206\ttotal: 2.02s\tremaining: 1m 38s\n",
      "20:\tlearn: 0.6599400\ttotal: 2.15s\tremaining: 1m 40s\n",
      "21:\tlearn: 0.6595153\ttotal: 2.28s\tremaining: 1m 41s\n",
      "22:\tlearn: 0.6591804\ttotal: 2.36s\tremaining: 1m 40s\n",
      "23:\tlearn: 0.6588872\ttotal: 2.45s\tremaining: 1m 39s\n",
      "24:\tlearn: 0.6585644\ttotal: 2.53s\tremaining: 1m 38s\n",
      "25:\tlearn: 0.6582422\ttotal: 2.6s\tremaining: 1m 37s\n",
      "26:\tlearn: 0.6579444\ttotal: 2.67s\tremaining: 1m 36s\n",
      "27:\tlearn: 0.6576604\ttotal: 2.75s\tremaining: 1m 35s\n",
      "28:\tlearn: 0.6573967\ttotal: 2.83s\tremaining: 1m 34s\n",
      "29:\tlearn: 0.6571414\ttotal: 2.92s\tremaining: 1m 34s\n",
      "30:\tlearn: 0.6569702\ttotal: 3.01s\tremaining: 1m 34s\n",
      "31:\tlearn: 0.6567020\ttotal: 3.09s\tremaining: 1m 33s\n",
      "32:\tlearn: 0.6565173\ttotal: 3.21s\tremaining: 1m 34s\n",
      "33:\tlearn: 0.6563229\ttotal: 3.31s\tremaining: 1m 34s\n",
      "34:\tlearn: 0.6561729\ttotal: 3.39s\tremaining: 1m 33s\n",
      "35:\tlearn: 0.6559144\ttotal: 3.53s\tremaining: 1m 34s\n",
      "36:\tlearn: 0.6556885\ttotal: 3.61s\tremaining: 1m 33s\n",
      "37:\tlearn: 0.6554631\ttotal: 3.71s\tremaining: 1m 34s\n",
      "38:\tlearn: 0.6552007\ttotal: 3.82s\tremaining: 1m 34s\n",
      "39:\tlearn: 0.6549820\ttotal: 3.89s\tremaining: 1m 33s\n",
      "40:\tlearn: 0.6548018\ttotal: 3.96s\tremaining: 1m 32s\n",
      "41:\tlearn: 0.6546236\ttotal: 4.08s\tremaining: 1m 33s\n",
      "42:\tlearn: 0.6543760\ttotal: 4.17s\tremaining: 1m 32s\n",
      "43:\tlearn: 0.6541861\ttotal: 4.24s\tremaining: 1m 32s\n",
      "44:\tlearn: 0.6540526\ttotal: 4.33s\tremaining: 1m 31s\n",
      "45:\tlearn: 0.6539090\ttotal: 4.41s\tremaining: 1m 31s\n",
      "46:\tlearn: 0.6537684\ttotal: 4.49s\tremaining: 1m 31s\n",
      "47:\tlearn: 0.6536694\ttotal: 4.58s\tremaining: 1m 30s\n",
      "48:\tlearn: 0.6534748\ttotal: 4.68s\tremaining: 1m 30s\n",
      "49:\tlearn: 0.6533621\ttotal: 4.76s\tremaining: 1m 30s\n",
      "50:\tlearn: 0.6532233\ttotal: 4.84s\tremaining: 1m 30s\n",
      "51:\tlearn: 0.6531124\ttotal: 4.95s\tremaining: 1m 30s\n",
      "52:\tlearn: 0.6529820\ttotal: 5.02s\tremaining: 1m 29s\n",
      "53:\tlearn: 0.6528696\ttotal: 5.14s\tremaining: 1m 29s\n",
      "54:\tlearn: 0.6527752\ttotal: 5.25s\tremaining: 1m 30s\n",
      "55:\tlearn: 0.6526643\ttotal: 5.37s\tremaining: 1m 30s\n",
      "56:\tlearn: 0.6524493\ttotal: 5.48s\tremaining: 1m 30s\n",
      "57:\tlearn: 0.6522821\ttotal: 5.57s\tremaining: 1m 30s\n",
      "58:\tlearn: 0.6521618\ttotal: 5.65s\tremaining: 1m 30s\n",
      "59:\tlearn: 0.6520375\ttotal: 5.76s\tremaining: 1m 30s\n",
      "60:\tlearn: 0.6519373\ttotal: 5.83s\tremaining: 1m 29s\n",
      "61:\tlearn: 0.6517761\ttotal: 5.92s\tremaining: 1m 29s\n",
      "62:\tlearn: 0.6515235\ttotal: 6.03s\tremaining: 1m 29s\n",
      "63:\tlearn: 0.6514408\ttotal: 6.1s\tremaining: 1m 29s\n",
      "64:\tlearn: 0.6513334\ttotal: 6.2s\tremaining: 1m 29s\n",
      "65:\tlearn: 0.6512607\ttotal: 6.26s\tremaining: 1m 28s\n",
      "66:\tlearn: 0.6511431\ttotal: 6.33s\tremaining: 1m 28s\n",
      "67:\tlearn: 0.6510461\ttotal: 6.41s\tremaining: 1m 27s\n",
      "68:\tlearn: 0.6509590\ttotal: 6.51s\tremaining: 1m 27s\n",
      "69:\tlearn: 0.6508608\ttotal: 6.59s\tremaining: 1m 27s\n",
      "70:\tlearn: 0.6507380\ttotal: 6.66s\tremaining: 1m 27s\n",
      "71:\tlearn: 0.6506091\ttotal: 6.75s\tremaining: 1m 26s\n",
      "72:\tlearn: 0.6505352\ttotal: 6.85s\tremaining: 1m 27s\n",
      "73:\tlearn: 0.6504297\ttotal: 6.92s\tremaining: 1m 26s\n",
      "74:\tlearn: 0.6503177\ttotal: 7s\tremaining: 1m 26s\n",
      "75:\tlearn: 0.6502168\ttotal: 7.08s\tremaining: 1m 26s\n",
      "76:\tlearn: 0.6501503\ttotal: 7.17s\tremaining: 1m 25s\n",
      "77:\tlearn: 0.6500011\ttotal: 7.26s\tremaining: 1m 25s\n",
      "78:\tlearn: 0.6498899\ttotal: 7.34s\tremaining: 1m 25s\n",
      "79:\tlearn: 0.6497836\ttotal: 7.42s\tremaining: 1m 25s\n",
      "80:\tlearn: 0.6496892\ttotal: 7.52s\tremaining: 1m 25s\n",
      "81:\tlearn: 0.6496157\ttotal: 7.62s\tremaining: 1m 25s\n",
      "82:\tlearn: 0.6495130\ttotal: 7.75s\tremaining: 1m 25s\n",
      "83:\tlearn: 0.6494300\ttotal: 7.88s\tremaining: 1m 25s\n",
      "84:\tlearn: 0.6493676\ttotal: 7.99s\tremaining: 1m 26s\n",
      "85:\tlearn: 0.6492496\ttotal: 8.09s\tremaining: 1m 25s\n",
      "86:\tlearn: 0.6491044\ttotal: 8.19s\tremaining: 1m 25s\n",
      "87:\tlearn: 0.6490016\ttotal: 8.33s\tremaining: 1m 26s\n",
      "88:\tlearn: 0.6489537\ttotal: 8.4s\tremaining: 1m 25s\n",
      "89:\tlearn: 0.6488102\ttotal: 8.49s\tremaining: 1m 25s\n",
      "90:\tlearn: 0.6487207\ttotal: 8.57s\tremaining: 1m 25s\n",
      "91:\tlearn: 0.6486404\ttotal: 8.66s\tremaining: 1m 25s\n",
      "92:\tlearn: 0.6485170\ttotal: 8.74s\tremaining: 1m 25s\n",
      "93:\tlearn: 0.6483824\ttotal: 8.83s\tremaining: 1m 25s\n",
      "94:\tlearn: 0.6482747\ttotal: 8.92s\tremaining: 1m 24s\n",
      "95:\tlearn: 0.6481771\ttotal: 9s\tremaining: 1m 24s\n",
      "96:\tlearn: 0.6479862\ttotal: 9.08s\tremaining: 1m 24s\n",
      "97:\tlearn: 0.6479107\ttotal: 9.17s\tremaining: 1m 24s\n",
      "98:\tlearn: 0.6478093\ttotal: 9.24s\tremaining: 1m 24s\n",
      "99:\tlearn: 0.6477466\ttotal: 9.31s\tremaining: 1m 23s\n",
      "100:\tlearn: 0.6476033\ttotal: 9.4s\tremaining: 1m 23s\n",
      "101:\tlearn: 0.6474925\ttotal: 9.47s\tremaining: 1m 23s\n",
      "102:\tlearn: 0.6474070\ttotal: 9.57s\tremaining: 1m 23s\n",
      "103:\tlearn: 0.6473313\ttotal: 9.66s\tremaining: 1m 23s\n",
      "104:\tlearn: 0.6472454\ttotal: 9.79s\tremaining: 1m 23s\n",
      "105:\tlearn: 0.6471709\ttotal: 9.98s\tremaining: 1m 24s\n",
      "106:\tlearn: 0.6470710\ttotal: 10.1s\tremaining: 1m 24s\n",
      "107:\tlearn: 0.6470036\ttotal: 10.2s\tremaining: 1m 24s\n",
      "108:\tlearn: 0.6469393\ttotal: 10.3s\tremaining: 1m 23s\n",
      "109:\tlearn: 0.6468637\ttotal: 10.3s\tremaining: 1m 23s\n",
      "110:\tlearn: 0.6467782\ttotal: 10.4s\tremaining: 1m 23s\n",
      "111:\tlearn: 0.6466722\ttotal: 10.5s\tremaining: 1m 23s\n",
      "112:\tlearn: 0.6465852\ttotal: 10.6s\tremaining: 1m 23s\n",
      "113:\tlearn: 0.6465320\ttotal: 10.7s\tremaining: 1m 22s\n",
      "114:\tlearn: 0.6464845\ttotal: 10.7s\tremaining: 1m 22s\n",
      "115:\tlearn: 0.6463741\ttotal: 10.8s\tremaining: 1m 22s\n",
      "116:\tlearn: 0.6462766\ttotal: 10.9s\tremaining: 1m 22s\n",
      "117:\tlearn: 0.6462030\ttotal: 11s\tremaining: 1m 22s\n",
      "118:\tlearn: 0.6461004\ttotal: 11.1s\tremaining: 1m 22s\n",
      "119:\tlearn: 0.6460423\ttotal: 11.2s\tremaining: 1m 22s\n",
      "120:\tlearn: 0.6459626\ttotal: 11.3s\tremaining: 1m 22s\n",
      "121:\tlearn: 0.6458883\ttotal: 11.4s\tremaining: 1m 21s\n",
      "122:\tlearn: 0.6458214\ttotal: 11.5s\tremaining: 1m 21s\n",
      "123:\tlearn: 0.6457448\ttotal: 11.6s\tremaining: 1m 21s\n",
      "124:\tlearn: 0.6456778\ttotal: 11.7s\tremaining: 1m 21s\n",
      "125:\tlearn: 0.6456282\ttotal: 11.8s\tremaining: 1m 21s\n",
      "126:\tlearn: 0.6455677\ttotal: 11.9s\tremaining: 1m 22s\n",
      "127:\tlearn: 0.6454064\ttotal: 12.1s\tremaining: 1m 22s\n",
      "128:\tlearn: 0.6453529\ttotal: 12.2s\tremaining: 1m 22s\n",
      "129:\tlearn: 0.6452964\ttotal: 12.3s\tremaining: 1m 22s\n",
      "130:\tlearn: 0.6452220\ttotal: 12.4s\tremaining: 1m 22s\n",
      "131:\tlearn: 0.6451512\ttotal: 12.5s\tremaining: 1m 22s\n",
      "132:\tlearn: 0.6450748\ttotal: 12.6s\tremaining: 1m 22s\n",
      "133:\tlearn: 0.6450035\ttotal: 12.8s\tremaining: 1m 22s\n",
      "134:\tlearn: 0.6449354\ttotal: 12.9s\tremaining: 1m 22s\n",
      "135:\tlearn: 0.6448698\ttotal: 13s\tremaining: 1m 22s\n",
      "136:\tlearn: 0.6447582\ttotal: 13.1s\tremaining: 1m 22s\n",
      "137:\tlearn: 0.6446607\ttotal: 13.2s\tremaining: 1m 22s\n",
      "138:\tlearn: 0.6446130\ttotal: 13.3s\tremaining: 1m 22s\n",
      "139:\tlearn: 0.6445398\ttotal: 13.4s\tremaining: 1m 22s\n",
      "140:\tlearn: 0.6444639\ttotal: 13.5s\tremaining: 1m 22s\n",
      "141:\tlearn: 0.6444034\ttotal: 13.6s\tremaining: 1m 22s\n",
      "142:\tlearn: 0.6443558\ttotal: 13.7s\tremaining: 1m 22s\n",
      "143:\tlearn: 0.6442915\ttotal: 13.8s\tremaining: 1m 22s\n",
      "144:\tlearn: 0.6442293\ttotal: 13.9s\tremaining: 1m 21s\n",
      "145:\tlearn: 0.6441702\ttotal: 14s\tremaining: 1m 21s\n",
      "146:\tlearn: 0.6440675\ttotal: 14s\tremaining: 1m 21s\n",
      "147:\tlearn: 0.6440144\ttotal: 14.1s\tremaining: 1m 21s\n",
      "148:\tlearn: 0.6439473\ttotal: 14.3s\tremaining: 1m 21s\n",
      "149:\tlearn: 0.6438848\ttotal: 14.4s\tremaining: 1m 21s\n",
      "150:\tlearn: 0.6438199\ttotal: 14.5s\tremaining: 1m 21s\n",
      "151:\tlearn: 0.6437568\ttotal: 14.6s\tremaining: 1m 21s\n",
      "152:\tlearn: 0.6437133\ttotal: 14.6s\tremaining: 1m 21s\n",
      "153:\tlearn: 0.6436444\ttotal: 14.7s\tremaining: 1m 20s\n",
      "154:\tlearn: 0.6435470\ttotal: 14.8s\tremaining: 1m 20s\n",
      "155:\tlearn: 0.6434716\ttotal: 15s\tremaining: 1m 21s\n",
      "156:\tlearn: 0.6433952\ttotal: 15.1s\tremaining: 1m 21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157:\tlearn: 0.6433376\ttotal: 15.2s\tremaining: 1m 20s\n",
      "158:\tlearn: 0.6432717\ttotal: 15.3s\tremaining: 1m 20s\n",
      "159:\tlearn: 0.6432187\ttotal: 15.4s\tremaining: 1m 20s\n",
      "160:\tlearn: 0.6431805\ttotal: 15.5s\tremaining: 1m 20s\n",
      "161:\tlearn: 0.6431271\ttotal: 15.6s\tremaining: 1m 20s\n",
      "162:\tlearn: 0.6430828\ttotal: 15.7s\tremaining: 1m 20s\n",
      "163:\tlearn: 0.6430172\ttotal: 15.8s\tremaining: 1m 20s\n",
      "164:\tlearn: 0.6429685\ttotal: 15.8s\tremaining: 1m 20s\n",
      "165:\tlearn: 0.6429289\ttotal: 15.9s\tremaining: 1m 19s\n",
      "166:\tlearn: 0.6428742\ttotal: 16s\tremaining: 1m 19s\n",
      "167:\tlearn: 0.6428246\ttotal: 16.1s\tremaining: 1m 19s\n",
      "168:\tlearn: 0.6427420\ttotal: 16.2s\tremaining: 1m 19s\n",
      "169:\tlearn: 0.6426720\ttotal: 16.2s\tremaining: 1m 19s\n",
      "170:\tlearn: 0.6426113\ttotal: 16.3s\tremaining: 1m 19s\n",
      "171:\tlearn: 0.6425633\ttotal: 16.4s\tremaining: 1m 19s\n",
      "172:\tlearn: 0.6425125\ttotal: 16.5s\tremaining: 1m 18s\n",
      "173:\tlearn: 0.6424513\ttotal: 16.6s\tremaining: 1m 18s\n",
      "174:\tlearn: 0.6424159\ttotal: 16.7s\tremaining: 1m 18s\n",
      "175:\tlearn: 0.6423525\ttotal: 16.8s\tremaining: 1m 18s\n",
      "176:\tlearn: 0.6423085\ttotal: 16.8s\tremaining: 1m 18s\n",
      "177:\tlearn: 0.6422468\ttotal: 16.9s\tremaining: 1m 18s\n",
      "178:\tlearn: 0.6421858\ttotal: 17s\tremaining: 1m 17s\n",
      "179:\tlearn: 0.6421311\ttotal: 17.1s\tremaining: 1m 17s\n",
      "180:\tlearn: 0.6420839\ttotal: 17.2s\tremaining: 1m 17s\n",
      "181:\tlearn: 0.6420282\ttotal: 17.3s\tremaining: 1m 17s\n",
      "182:\tlearn: 0.6419720\ttotal: 17.4s\tremaining: 1m 17s\n",
      "183:\tlearn: 0.6419107\ttotal: 17.5s\tremaining: 1m 17s\n",
      "184:\tlearn: 0.6418444\ttotal: 17.6s\tremaining: 1m 17s\n",
      "185:\tlearn: 0.6417950\ttotal: 17.6s\tremaining: 1m 17s\n",
      "186:\tlearn: 0.6417527\ttotal: 17.7s\tremaining: 1m 17s\n",
      "187:\tlearn: 0.6417051\ttotal: 17.8s\tremaining: 1m 16s\n",
      "188:\tlearn: 0.6416517\ttotal: 17.9s\tremaining: 1m 16s\n",
      "189:\tlearn: 0.6415598\ttotal: 18s\tremaining: 1m 16s\n",
      "190:\tlearn: 0.6415159\ttotal: 18.1s\tremaining: 1m 16s\n",
      "191:\tlearn: 0.6414830\ttotal: 18.2s\tremaining: 1m 16s\n",
      "192:\tlearn: 0.6414427\ttotal: 18.3s\tremaining: 1m 16s\n",
      "193:\tlearn: 0.6413886\ttotal: 18.4s\tremaining: 1m 16s\n",
      "194:\tlearn: 0.6413368\ttotal: 18.5s\tremaining: 1m 16s\n",
      "195:\tlearn: 0.6412777\ttotal: 18.6s\tremaining: 1m 16s\n",
      "196:\tlearn: 0.6412225\ttotal: 18.6s\tremaining: 1m 15s\n",
      "197:\tlearn: 0.6411678\ttotal: 18.7s\tremaining: 1m 15s\n",
      "198:\tlearn: 0.6411144\ttotal: 18.8s\tremaining: 1m 15s\n",
      "199:\tlearn: 0.6410660\ttotal: 18.9s\tremaining: 1m 15s\n",
      "200:\tlearn: 0.6410216\ttotal: 19s\tremaining: 1m 15s\n",
      "201:\tlearn: 0.6409601\ttotal: 19.1s\tremaining: 1m 15s\n",
      "202:\tlearn: 0.6409151\ttotal: 19.2s\tremaining: 1m 15s\n",
      "203:\tlearn: 0.6408459\ttotal: 19.3s\tremaining: 1m 15s\n",
      "204:\tlearn: 0.6407923\ttotal: 19.4s\tremaining: 1m 15s\n",
      "205:\tlearn: 0.6407332\ttotal: 19.5s\tremaining: 1m 15s\n",
      "206:\tlearn: 0.6406985\ttotal: 19.6s\tremaining: 1m 15s\n",
      "207:\tlearn: 0.6406543\ttotal: 19.7s\tremaining: 1m 14s\n",
      "208:\tlearn: 0.6406015\ttotal: 19.7s\tremaining: 1m 14s\n",
      "209:\tlearn: 0.6405548\ttotal: 19.8s\tremaining: 1m 14s\n",
      "210:\tlearn: 0.6405113\ttotal: 19.9s\tremaining: 1m 14s\n",
      "211:\tlearn: 0.6404553\ttotal: 20s\tremaining: 1m 14s\n",
      "212:\tlearn: 0.6403650\ttotal: 20.1s\tremaining: 1m 14s\n",
      "213:\tlearn: 0.6403237\ttotal: 20.2s\tremaining: 1m 14s\n",
      "214:\tlearn: 0.6402760\ttotal: 20.2s\tremaining: 1m 13s\n",
      "215:\tlearn: 0.6402233\ttotal: 20.3s\tremaining: 1m 13s\n",
      "216:\tlearn: 0.6401771\ttotal: 20.4s\tremaining: 1m 13s\n",
      "217:\tlearn: 0.6401147\ttotal: 20.5s\tremaining: 1m 13s\n",
      "218:\tlearn: 0.6400808\ttotal: 20.6s\tremaining: 1m 13s\n",
      "219:\tlearn: 0.6400397\ttotal: 20.7s\tremaining: 1m 13s\n",
      "220:\tlearn: 0.6399828\ttotal: 20.8s\tremaining: 1m 13s\n",
      "221:\tlearn: 0.6399293\ttotal: 20.9s\tremaining: 1m 13s\n",
      "222:\tlearn: 0.6398881\ttotal: 21s\tremaining: 1m 13s\n",
      "223:\tlearn: 0.6398514\ttotal: 21.1s\tremaining: 1m 13s\n",
      "224:\tlearn: 0.6398020\ttotal: 21.2s\tremaining: 1m 12s\n",
      "225:\tlearn: 0.6397535\ttotal: 21.3s\tremaining: 1m 12s\n",
      "226:\tlearn: 0.6397061\ttotal: 21.3s\tremaining: 1m 12s\n",
      "227:\tlearn: 0.6396589\ttotal: 21.4s\tremaining: 1m 12s\n",
      "228:\tlearn: 0.6395993\ttotal: 21.5s\tremaining: 1m 12s\n",
      "229:\tlearn: 0.6395490\ttotal: 21.6s\tremaining: 1m 12s\n",
      "230:\tlearn: 0.6395065\ttotal: 21.7s\tremaining: 1m 12s\n",
      "231:\tlearn: 0.6394637\ttotal: 21.8s\tremaining: 1m 12s\n",
      "232:\tlearn: 0.6393865\ttotal: 21.9s\tremaining: 1m 11s\n",
      "233:\tlearn: 0.6393537\ttotal: 21.9s\tremaining: 1m 11s\n",
      "234:\tlearn: 0.6393004\ttotal: 22s\tremaining: 1m 11s\n",
      "235:\tlearn: 0.6392538\ttotal: 22.1s\tremaining: 1m 11s\n",
      "236:\tlearn: 0.6392214\ttotal: 22.2s\tremaining: 1m 11s\n",
      "237:\tlearn: 0.6391746\ttotal: 22.3s\tremaining: 1m 11s\n",
      "238:\tlearn: 0.6391436\ttotal: 22.4s\tremaining: 1m 11s\n",
      "239:\tlearn: 0.6391128\ttotal: 22.4s\tremaining: 1m 11s\n",
      "240:\tlearn: 0.6390582\ttotal: 22.5s\tremaining: 1m 10s\n",
      "241:\tlearn: 0.6390163\ttotal: 22.7s\tremaining: 1m 10s\n",
      "242:\tlearn: 0.6389819\ttotal: 22.7s\tremaining: 1m 10s\n",
      "243:\tlearn: 0.6389394\ttotal: 22.8s\tremaining: 1m 10s\n",
      "244:\tlearn: 0.6389085\ttotal: 22.9s\tremaining: 1m 10s\n",
      "245:\tlearn: 0.6388745\ttotal: 23s\tremaining: 1m 10s\n",
      "246:\tlearn: 0.6388268\ttotal: 23.1s\tremaining: 1m 10s\n",
      "247:\tlearn: 0.6387740\ttotal: 23.2s\tremaining: 1m 10s\n",
      "248:\tlearn: 0.6387422\ttotal: 23.3s\tremaining: 1m 10s\n",
      "249:\tlearn: 0.6386992\ttotal: 23.3s\tremaining: 1m 10s\n",
      "250:\tlearn: 0.6386605\ttotal: 23.4s\tremaining: 1m 9s\n",
      "251:\tlearn: 0.6386294\ttotal: 23.5s\tremaining: 1m 9s\n",
      "252:\tlearn: 0.6385724\ttotal: 23.6s\tremaining: 1m 9s\n",
      "253:\tlearn: 0.6385088\ttotal: 23.7s\tremaining: 1m 9s\n",
      "254:\tlearn: 0.6384652\ttotal: 23.8s\tremaining: 1m 9s\n",
      "255:\tlearn: 0.6384224\ttotal: 23.9s\tremaining: 1m 9s\n",
      "256:\tlearn: 0.6383740\ttotal: 24s\tremaining: 1m 9s\n",
      "257:\tlearn: 0.6383332\ttotal: 24.1s\tremaining: 1m 9s\n",
      "258:\tlearn: 0.6383064\ttotal: 24.2s\tremaining: 1m 9s\n",
      "259:\tlearn: 0.6382485\ttotal: 24.2s\tremaining: 1m 9s\n",
      "260:\tlearn: 0.6382157\ttotal: 24.4s\tremaining: 1m 8s\n",
      "261:\tlearn: 0.6381319\ttotal: 24.4s\tremaining: 1m 8s\n",
      "262:\tlearn: 0.6380927\ttotal: 24.5s\tremaining: 1m 8s\n",
      "263:\tlearn: 0.6380425\ttotal: 24.6s\tremaining: 1m 8s\n",
      "264:\tlearn: 0.6380095\ttotal: 24.7s\tremaining: 1m 8s\n",
      "265:\tlearn: 0.6379759\ttotal: 24.8s\tremaining: 1m 8s\n",
      "266:\tlearn: 0.6379216\ttotal: 24.8s\tremaining: 1m 8s\n",
      "267:\tlearn: 0.6378764\ttotal: 24.9s\tremaining: 1m 8s\n",
      "268:\tlearn: 0.6378010\ttotal: 25s\tremaining: 1m 7s\n",
      "269:\tlearn: 0.6377613\ttotal: 25.1s\tremaining: 1m 7s\n",
      "270:\tlearn: 0.6377122\ttotal: 25.1s\tremaining: 1m 7s\n",
      "271:\tlearn: 0.6376623\ttotal: 25.2s\tremaining: 1m 7s\n",
      "272:\tlearn: 0.6376313\ttotal: 25.3s\tremaining: 1m 7s\n",
      "273:\tlearn: 0.6375892\ttotal: 25.4s\tremaining: 1m 7s\n",
      "274:\tlearn: 0.6375391\ttotal: 25.5s\tremaining: 1m 7s\n",
      "275:\tlearn: 0.6375010\ttotal: 25.5s\tremaining: 1m 6s\n",
      "276:\tlearn: 0.6374586\ttotal: 25.6s\tremaining: 1m 6s\n",
      "277:\tlearn: 0.6373859\ttotal: 25.7s\tremaining: 1m 6s\n",
      "278:\tlearn: 0.6373315\ttotal: 25.8s\tremaining: 1m 6s\n",
      "279:\tlearn: 0.6372932\ttotal: 25.9s\tremaining: 1m 6s\n",
      "280:\tlearn: 0.6372610\ttotal: 26.1s\tremaining: 1m 6s\n",
      "281:\tlearn: 0.6372221\ttotal: 26.1s\tremaining: 1m 6s\n",
      "282:\tlearn: 0.6371816\ttotal: 26.2s\tremaining: 1m 6s\n",
      "283:\tlearn: 0.6371410\ttotal: 26.3s\tremaining: 1m 6s\n",
      "284:\tlearn: 0.6370999\ttotal: 26.4s\tremaining: 1m 6s\n",
      "285:\tlearn: 0.6370664\ttotal: 26.5s\tremaining: 1m 6s\n",
      "286:\tlearn: 0.6370177\ttotal: 26.6s\tremaining: 1m 5s\n",
      "287:\tlearn: 0.6369659\ttotal: 26.7s\tremaining: 1m 5s\n",
      "288:\tlearn: 0.6369251\ttotal: 26.7s\tremaining: 1m 5s\n",
      "289:\tlearn: 0.6368833\ttotal: 26.8s\tremaining: 1m 5s\n",
      "290:\tlearn: 0.6368463\ttotal: 26.9s\tremaining: 1m 5s\n",
      "291:\tlearn: 0.6368087\ttotal: 27s\tremaining: 1m 5s\n",
      "292:\tlearn: 0.6367656\ttotal: 27.1s\tremaining: 1m 5s\n",
      "293:\tlearn: 0.6367288\ttotal: 27.2s\tremaining: 1m 5s\n",
      "294:\tlearn: 0.6366995\ttotal: 27.3s\tremaining: 1m 5s\n",
      "295:\tlearn: 0.6366697\ttotal: 27.4s\tremaining: 1m 5s\n",
      "296:\tlearn: 0.6366277\ttotal: 27.5s\tremaining: 1m 5s\n",
      "297:\tlearn: 0.6365706\ttotal: 27.6s\tremaining: 1m 5s\n",
      "298:\tlearn: 0.6365299\ttotal: 27.7s\tremaining: 1m 5s\n",
      "299:\tlearn: 0.6364920\ttotal: 27.9s\tremaining: 1m 5s\n",
      "300:\tlearn: 0.6364499\ttotal: 27.9s\tremaining: 1m 4s\n",
      "301:\tlearn: 0.6364090\ttotal: 28s\tremaining: 1m 4s\n",
      "302:\tlearn: 0.6363714\ttotal: 28.1s\tremaining: 1m 4s\n",
      "303:\tlearn: 0.6363436\ttotal: 28.2s\tremaining: 1m 4s\n",
      "304:\tlearn: 0.6363014\ttotal: 28.3s\tremaining: 1m 4s\n",
      "305:\tlearn: 0.6362635\ttotal: 28.3s\tremaining: 1m 4s\n",
      "306:\tlearn: 0.6362333\ttotal: 28.5s\tremaining: 1m 4s\n",
      "307:\tlearn: 0.6361927\ttotal: 28.6s\tremaining: 1m 4s\n",
      "308:\tlearn: 0.6361446\ttotal: 28.6s\tremaining: 1m 4s\n",
      "309:\tlearn: 0.6361024\ttotal: 28.7s\tremaining: 1m 3s\n",
      "310:\tlearn: 0.6360665\ttotal: 28.8s\tremaining: 1m 3s\n",
      "311:\tlearn: 0.6360202\ttotal: 28.9s\tremaining: 1m 3s\n",
      "312:\tlearn: 0.6359828\ttotal: 29s\tremaining: 1m 3s\n",
      "313:\tlearn: 0.6359491\ttotal: 29s\tremaining: 1m 3s\n",
      "314:\tlearn: 0.6358973\ttotal: 29.1s\tremaining: 1m 3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315:\tlearn: 0.6358562\ttotal: 29.2s\tremaining: 1m 3s\n",
      "316:\tlearn: 0.6358274\ttotal: 29.3s\tremaining: 1m 3s\n",
      "317:\tlearn: 0.6357902\ttotal: 29.4s\tremaining: 1m 3s\n",
      "318:\tlearn: 0.6357538\ttotal: 29.5s\tremaining: 1m 2s\n",
      "319:\tlearn: 0.6357114\ttotal: 29.6s\tremaining: 1m 2s\n",
      "320:\tlearn: 0.6356719\ttotal: 29.7s\tremaining: 1m 2s\n",
      "321:\tlearn: 0.6356373\ttotal: 29.8s\tremaining: 1m 2s\n",
      "322:\tlearn: 0.6356087\ttotal: 29.8s\tremaining: 1m 2s\n",
      "323:\tlearn: 0.6355585\ttotal: 29.9s\tremaining: 1m 2s\n",
      "324:\tlearn: 0.6355289\ttotal: 30s\tremaining: 1m 2s\n",
      "325:\tlearn: 0.6354940\ttotal: 30.1s\tremaining: 1m 2s\n",
      "326:\tlearn: 0.6354437\ttotal: 30.2s\tremaining: 1m 2s\n",
      "327:\tlearn: 0.6354074\ttotal: 30.3s\tremaining: 1m 2s\n",
      "328:\tlearn: 0.6353702\ttotal: 30.4s\tremaining: 1m 2s\n",
      "329:\tlearn: 0.6353345\ttotal: 30.5s\tremaining: 1m 1s\n",
      "330:\tlearn: 0.6352880\ttotal: 30.6s\tremaining: 1m 1s\n",
      "331:\tlearn: 0.6352513\ttotal: 30.6s\tremaining: 1m 1s\n",
      "332:\tlearn: 0.6352093\ttotal: 30.7s\tremaining: 1m 1s\n",
      "333:\tlearn: 0.6351445\ttotal: 30.8s\tremaining: 1m 1s\n",
      "334:\tlearn: 0.6350995\ttotal: 30.9s\tremaining: 1m 1s\n",
      "335:\tlearn: 0.6350546\ttotal: 31s\tremaining: 1m 1s\n",
      "336:\tlearn: 0.6350262\ttotal: 31.1s\tremaining: 1m 1s\n",
      "337:\tlearn: 0.6349792\ttotal: 31.2s\tremaining: 1m 1s\n",
      "338:\tlearn: 0.6349484\ttotal: 31.3s\tremaining: 1m\n",
      "339:\tlearn: 0.6349097\ttotal: 31.3s\tremaining: 1m\n",
      "340:\tlearn: 0.6348689\ttotal: 31.4s\tremaining: 1m\n",
      "341:\tlearn: 0.6348285\ttotal: 31.5s\tremaining: 1m\n",
      "342:\tlearn: 0.6347961\ttotal: 31.6s\tremaining: 1m\n",
      "343:\tlearn: 0.6347668\ttotal: 31.7s\tremaining: 1m\n",
      "344:\tlearn: 0.6347344\ttotal: 31.8s\tremaining: 1m\n",
      "345:\tlearn: 0.6346993\ttotal: 31.8s\tremaining: 1m\n",
      "346:\tlearn: 0.6346426\ttotal: 31.9s\tremaining: 1m\n",
      "347:\tlearn: 0.6346150\ttotal: 32s\tremaining: 1m\n",
      "348:\tlearn: 0.6345767\ttotal: 32.1s\tremaining: 59.9s\n",
      "349:\tlearn: 0.6345328\ttotal: 32.2s\tremaining: 59.9s\n",
      "350:\tlearn: 0.6344745\ttotal: 32.4s\tremaining: 59.8s\n",
      "351:\tlearn: 0.6344426\ttotal: 32.5s\tremaining: 59.8s\n",
      "352:\tlearn: 0.6344083\ttotal: 32.6s\tremaining: 59.7s\n",
      "353:\tlearn: 0.6343706\ttotal: 32.7s\tremaining: 59.7s\n",
      "354:\tlearn: 0.6343341\ttotal: 32.8s\tremaining: 59.5s\n",
      "355:\tlearn: 0.6342793\ttotal: 32.9s\tremaining: 59.5s\n",
      "356:\tlearn: 0.6342479\ttotal: 33s\tremaining: 59.4s\n",
      "357:\tlearn: 0.6341994\ttotal: 33.1s\tremaining: 59.3s\n",
      "358:\tlearn: 0.6341593\ttotal: 33.2s\tremaining: 59.2s\n",
      "359:\tlearn: 0.6341354\ttotal: 33.2s\tremaining: 59.1s\n",
      "360:\tlearn: 0.6340970\ttotal: 33.3s\tremaining: 59s\n",
      "361:\tlearn: 0.6340699\ttotal: 33.4s\tremaining: 58.9s\n",
      "362:\tlearn: 0.6340295\ttotal: 33.5s\tremaining: 58.8s\n",
      "363:\tlearn: 0.6339961\ttotal: 33.6s\tremaining: 58.7s\n",
      "364:\tlearn: 0.6339636\ttotal: 33.7s\tremaining: 58.6s\n",
      "365:\tlearn: 0.6339386\ttotal: 33.7s\tremaining: 58.4s\n",
      "366:\tlearn: 0.6339123\ttotal: 33.8s\tremaining: 58.3s\n",
      "367:\tlearn: 0.6338680\ttotal: 33.9s\tremaining: 58.2s\n",
      "368:\tlearn: 0.6338370\ttotal: 34s\tremaining: 58.1s\n",
      "369:\tlearn: 0.6338021\ttotal: 34s\tremaining: 58s\n",
      "370:\tlearn: 0.6337636\ttotal: 34.1s\tremaining: 57.8s\n",
      "371:\tlearn: 0.6337080\ttotal: 34.2s\tremaining: 57.7s\n",
      "372:\tlearn: 0.6336599\ttotal: 34.3s\tremaining: 57.6s\n",
      "373:\tlearn: 0.6336201\ttotal: 34.3s\tremaining: 57.5s\n",
      "374:\tlearn: 0.6335721\ttotal: 34.5s\tremaining: 57.5s\n",
      "375:\tlearn: 0.6335564\ttotal: 34.5s\tremaining: 57.3s\n",
      "376:\tlearn: 0.6335214\ttotal: 34.6s\tremaining: 57.2s\n",
      "377:\tlearn: 0.6334832\ttotal: 34.7s\tremaining: 57s\n",
      "378:\tlearn: 0.6334582\ttotal: 34.7s\tremaining: 56.9s\n",
      "379:\tlearn: 0.6334358\ttotal: 34.8s\tremaining: 56.8s\n",
      "380:\tlearn: 0.6333998\ttotal: 34.9s\tremaining: 56.7s\n",
      "381:\tlearn: 0.6333714\ttotal: 35s\tremaining: 56.6s\n",
      "382:\tlearn: 0.6333351\ttotal: 35.1s\tremaining: 56.5s\n",
      "383:\tlearn: 0.6333022\ttotal: 35.2s\tremaining: 56.5s\n",
      "384:\tlearn: 0.6332698\ttotal: 35.3s\tremaining: 56.3s\n",
      "385:\tlearn: 0.6332355\ttotal: 35.4s\tremaining: 56.3s\n",
      "386:\tlearn: 0.6332050\ttotal: 35.5s\tremaining: 56.2s\n",
      "387:\tlearn: 0.6331791\ttotal: 35.6s\tremaining: 56.1s\n",
      "388:\tlearn: 0.6331411\ttotal: 35.7s\tremaining: 56s\n",
      "389:\tlearn: 0.6331120\ttotal: 35.8s\tremaining: 55.9s\n",
      "390:\tlearn: 0.6330754\ttotal: 35.8s\tremaining: 55.8s\n",
      "391:\tlearn: 0.6330492\ttotal: 35.9s\tremaining: 55.7s\n",
      "392:\tlearn: 0.6330091\ttotal: 36s\tremaining: 55.6s\n",
      "393:\tlearn: 0.6329769\ttotal: 36.1s\tremaining: 55.5s\n",
      "394:\tlearn: 0.6329260\ttotal: 36.2s\tremaining: 55.4s\n",
      "395:\tlearn: 0.6328958\ttotal: 36.3s\tremaining: 55.3s\n",
      "396:\tlearn: 0.6328635\ttotal: 36.3s\tremaining: 55.2s\n",
      "397:\tlearn: 0.6328242\ttotal: 36.4s\tremaining: 55.1s\n",
      "398:\tlearn: 0.6327892\ttotal: 36.5s\tremaining: 55s\n",
      "399:\tlearn: 0.6327519\ttotal: 36.6s\tremaining: 54.9s\n",
      "400:\tlearn: 0.6327137\ttotal: 36.7s\tremaining: 54.9s\n",
      "401:\tlearn: 0.6326906\ttotal: 36.8s\tremaining: 54.8s\n",
      "402:\tlearn: 0.6326585\ttotal: 36.9s\tremaining: 54.7s\n",
      "403:\tlearn: 0.6326279\ttotal: 37s\tremaining: 54.6s\n",
      "404:\tlearn: 0.6325977\ttotal: 37.1s\tremaining: 54.5s\n",
      "405:\tlearn: 0.6325643\ttotal: 37.2s\tremaining: 54.4s\n",
      "406:\tlearn: 0.6325332\ttotal: 37.2s\tremaining: 54.2s\n",
      "407:\tlearn: 0.6325081\ttotal: 37.3s\tremaining: 54.1s\n",
      "408:\tlearn: 0.6324584\ttotal: 37.4s\tremaining: 54s\n",
      "409:\tlearn: 0.6324263\ttotal: 37.4s\tremaining: 53.9s\n",
      "410:\tlearn: 0.6323949\ttotal: 37.5s\tremaining: 53.8s\n",
      "411:\tlearn: 0.6323565\ttotal: 37.6s\tremaining: 53.7s\n",
      "412:\tlearn: 0.6323121\ttotal: 37.7s\tremaining: 53.6s\n",
      "413:\tlearn: 0.6322839\ttotal: 37.8s\tremaining: 53.5s\n",
      "414:\tlearn: 0.6322492\ttotal: 37.9s\tremaining: 53.4s\n",
      "415:\tlearn: 0.6322159\ttotal: 38s\tremaining: 53.3s\n",
      "416:\tlearn: 0.6321821\ttotal: 38s\tremaining: 53.2s\n",
      "417:\tlearn: 0.6321508\ttotal: 38.1s\tremaining: 53.1s\n",
      "418:\tlearn: 0.6321209\ttotal: 38.2s\tremaining: 53s\n",
      "419:\tlearn: 0.6320894\ttotal: 38.3s\tremaining: 52.9s\n",
      "420:\tlearn: 0.6320536\ttotal: 38.4s\tremaining: 52.9s\n",
      "421:\tlearn: 0.6320252\ttotal: 38.5s\tremaining: 52.8s\n",
      "422:\tlearn: 0.6319902\ttotal: 38.6s\tremaining: 52.7s\n",
      "423:\tlearn: 0.6319492\ttotal: 38.7s\tremaining: 52.6s\n",
      "424:\tlearn: 0.6319157\ttotal: 38.8s\tremaining: 52.5s\n",
      "425:\tlearn: 0.6318835\ttotal: 38.9s\tremaining: 52.5s\n",
      "426:\tlearn: 0.6318404\ttotal: 39s\tremaining: 52.4s\n",
      "427:\tlearn: 0.6317980\ttotal: 39.1s\tremaining: 52.3s\n",
      "428:\tlearn: 0.6317515\ttotal: 39.2s\tremaining: 52.2s\n",
      "429:\tlearn: 0.6317144\ttotal: 39.3s\tremaining: 52.1s\n",
      "430:\tlearn: 0.6316813\ttotal: 39.4s\tremaining: 52s\n",
      "431:\tlearn: 0.6316505\ttotal: 39.5s\tremaining: 51.9s\n",
      "432:\tlearn: 0.6316144\ttotal: 39.6s\tremaining: 51.8s\n",
      "433:\tlearn: 0.6315831\ttotal: 39.7s\tremaining: 51.7s\n",
      "434:\tlearn: 0.6315440\ttotal: 39.8s\tremaining: 51.7s\n",
      "435:\tlearn: 0.6314975\ttotal: 39.9s\tremaining: 51.6s\n",
      "436:\tlearn: 0.6314493\ttotal: 40s\tremaining: 51.5s\n",
      "437:\tlearn: 0.6314202\ttotal: 40s\tremaining: 51.4s\n",
      "438:\tlearn: 0.6313805\ttotal: 40.1s\tremaining: 51.3s\n",
      "439:\tlearn: 0.6313619\ttotal: 40.2s\tremaining: 51.1s\n",
      "440:\tlearn: 0.6313278\ttotal: 40.3s\tremaining: 51.1s\n",
      "441:\tlearn: 0.6312889\ttotal: 40.4s\tremaining: 51s\n",
      "442:\tlearn: 0.6312676\ttotal: 40.5s\tremaining: 50.9s\n",
      "443:\tlearn: 0.6312374\ttotal: 40.6s\tremaining: 50.8s\n",
      "444:\tlearn: 0.6312086\ttotal: 40.7s\tremaining: 50.7s\n",
      "445:\tlearn: 0.6311737\ttotal: 40.7s\tremaining: 50.6s\n",
      "446:\tlearn: 0.6311486\ttotal: 40.8s\tremaining: 50.5s\n",
      "447:\tlearn: 0.6311256\ttotal: 40.9s\tremaining: 50.4s\n",
      "448:\tlearn: 0.6310869\ttotal: 41s\tremaining: 50.3s\n",
      "449:\tlearn: 0.6310545\ttotal: 41.1s\tremaining: 50.2s\n",
      "450:\tlearn: 0.6310198\ttotal: 41.1s\tremaining: 50.1s\n",
      "451:\tlearn: 0.6309908\ttotal: 41.2s\tremaining: 50s\n",
      "452:\tlearn: 0.6309623\ttotal: 41.3s\tremaining: 49.9s\n",
      "453:\tlearn: 0.6309213\ttotal: 41.4s\tremaining: 49.8s\n",
      "454:\tlearn: 0.6308879\ttotal: 41.5s\tremaining: 49.7s\n",
      "455:\tlearn: 0.6308558\ttotal: 41.6s\tremaining: 49.6s\n",
      "456:\tlearn: 0.6307986\ttotal: 41.7s\tremaining: 49.5s\n",
      "457:\tlearn: 0.6307595\ttotal: 41.8s\tremaining: 49.5s\n",
      "458:\tlearn: 0.6307339\ttotal: 41.9s\tremaining: 49.3s\n",
      "459:\tlearn: 0.6306919\ttotal: 42s\tremaining: 49.3s\n",
      "460:\tlearn: 0.6306626\ttotal: 42.1s\tremaining: 49.2s\n",
      "461:\tlearn: 0.6306353\ttotal: 42.2s\tremaining: 49.1s\n",
      "462:\tlearn: 0.6306011\ttotal: 42.3s\tremaining: 49s\n",
      "463:\tlearn: 0.6305766\ttotal: 42.3s\tremaining: 48.9s\n",
      "464:\tlearn: 0.6305473\ttotal: 42.4s\tremaining: 48.8s\n",
      "465:\tlearn: 0.6305247\ttotal: 42.5s\tremaining: 48.7s\n",
      "466:\tlearn: 0.6304876\ttotal: 42.6s\tremaining: 48.6s\n",
      "467:\tlearn: 0.6304475\ttotal: 42.7s\tremaining: 48.5s\n",
      "468:\tlearn: 0.6304033\ttotal: 42.8s\tremaining: 48.4s\n",
      "469:\tlearn: 0.6303687\ttotal: 42.9s\tremaining: 48.4s\n",
      "470:\tlearn: 0.6303307\ttotal: 43s\tremaining: 48.3s\n",
      "471:\tlearn: 0.6303086\ttotal: 43.1s\tremaining: 48.2s\n",
      "472:\tlearn: 0.6302834\ttotal: 43.2s\tremaining: 48.1s\n",
      "473:\tlearn: 0.6302414\ttotal: 43.3s\tremaining: 48s\n",
      "474:\tlearn: 0.6302094\ttotal: 43.3s\tremaining: 47.9s\n",
      "475:\tlearn: 0.6301810\ttotal: 43.4s\tremaining: 47.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476:\tlearn: 0.6301583\ttotal: 43.5s\tremaining: 47.7s\n",
      "477:\tlearn: 0.6301355\ttotal: 43.6s\tremaining: 47.6s\n",
      "478:\tlearn: 0.6300979\ttotal: 43.7s\tremaining: 47.5s\n",
      "479:\tlearn: 0.6300661\ttotal: 43.8s\tremaining: 47.4s\n",
      "480:\tlearn: 0.6300313\ttotal: 43.9s\tremaining: 47.4s\n",
      "481:\tlearn: 0.6299966\ttotal: 44s\tremaining: 47.3s\n",
      "482:\tlearn: 0.6299727\ttotal: 44.1s\tremaining: 47.2s\n",
      "483:\tlearn: 0.6299520\ttotal: 44.2s\tremaining: 47.1s\n",
      "484:\tlearn: 0.6299190\ttotal: 44.2s\tremaining: 47s\n",
      "485:\tlearn: 0.6298792\ttotal: 44.3s\tremaining: 46.9s\n",
      "486:\tlearn: 0.6298573\ttotal: 44.4s\tremaining: 46.8s\n",
      "487:\tlearn: 0.6298274\ttotal: 44.5s\tremaining: 46.7s\n",
      "488:\tlearn: 0.6297988\ttotal: 44.6s\tremaining: 46.6s\n",
      "489:\tlearn: 0.6297524\ttotal: 44.7s\tremaining: 46.5s\n",
      "490:\tlearn: 0.6297245\ttotal: 44.7s\tremaining: 46.4s\n",
      "491:\tlearn: 0.6297054\ttotal: 44.9s\tremaining: 46.3s\n",
      "492:\tlearn: 0.6296750\ttotal: 44.9s\tremaining: 46.2s\n",
      "493:\tlearn: 0.6296402\ttotal: 45s\tremaining: 46.1s\n",
      "494:\tlearn: 0.6296085\ttotal: 45.1s\tremaining: 46s\n",
      "495:\tlearn: 0.6295650\ttotal: 45.2s\tremaining: 45.9s\n",
      "496:\tlearn: 0.6295288\ttotal: 45.2s\tremaining: 45.8s\n",
      "497:\tlearn: 0.6295012\ttotal: 45.4s\tremaining: 45.7s\n",
      "498:\tlearn: 0.6294692\ttotal: 45.4s\tremaining: 45.6s\n",
      "499:\tlearn: 0.6294414\ttotal: 45.5s\tremaining: 45.5s\n",
      "500:\tlearn: 0.6294162\ttotal: 45.6s\tremaining: 45.4s\n",
      "501:\tlearn: 0.6293769\ttotal: 45.7s\tremaining: 45.3s\n",
      "502:\tlearn: 0.6293401\ttotal: 45.8s\tremaining: 45.2s\n",
      "503:\tlearn: 0.6293143\ttotal: 45.9s\tremaining: 45.2s\n",
      "504:\tlearn: 0.6292892\ttotal: 46s\tremaining: 45.1s\n",
      "505:\tlearn: 0.6292354\ttotal: 46.1s\tremaining: 45s\n",
      "506:\tlearn: 0.6292099\ttotal: 46.1s\tremaining: 44.9s\n",
      "507:\tlearn: 0.6291684\ttotal: 46.2s\tremaining: 44.8s\n",
      "508:\tlearn: 0.6291412\ttotal: 46.3s\tremaining: 44.7s\n",
      "509:\tlearn: 0.6291042\ttotal: 46.5s\tremaining: 44.6s\n",
      "510:\tlearn: 0.6290676\ttotal: 46.6s\tremaining: 44.6s\n",
      "511:\tlearn: 0.6290164\ttotal: 46.7s\tremaining: 44.5s\n",
      "512:\tlearn: 0.6289836\ttotal: 46.8s\tremaining: 44.4s\n",
      "513:\tlearn: 0.6289502\ttotal: 46.8s\tremaining: 44.3s\n",
      "514:\tlearn: 0.6289307\ttotal: 47s\tremaining: 44.2s\n",
      "515:\tlearn: 0.6289006\ttotal: 47.1s\tremaining: 44.2s\n",
      "516:\tlearn: 0.6288762\ttotal: 47.2s\tremaining: 44.1s\n",
      "517:\tlearn: 0.6288521\ttotal: 47.3s\tremaining: 44s\n",
      "518:\tlearn: 0.6288290\ttotal: 47.4s\tremaining: 43.9s\n",
      "519:\tlearn: 0.6287931\ttotal: 47.5s\tremaining: 43.8s\n",
      "520:\tlearn: 0.6287603\ttotal: 47.6s\tremaining: 43.7s\n",
      "521:\tlearn: 0.6287217\ttotal: 47.7s\tremaining: 43.6s\n",
      "522:\tlearn: 0.6286905\ttotal: 47.7s\tremaining: 43.5s\n",
      "523:\tlearn: 0.6286731\ttotal: 47.8s\tremaining: 43.4s\n",
      "524:\tlearn: 0.6286404\ttotal: 47.9s\tremaining: 43.3s\n",
      "525:\tlearn: 0.6286143\ttotal: 48s\tremaining: 43.2s\n",
      "526:\tlearn: 0.6285826\ttotal: 48.1s\tremaining: 43.1s\n",
      "527:\tlearn: 0.6285480\ttotal: 48.2s\tremaining: 43.1s\n",
      "528:\tlearn: 0.6285175\ttotal: 48.3s\tremaining: 43s\n",
      "529:\tlearn: 0.6284799\ttotal: 48.4s\tremaining: 42.9s\n",
      "530:\tlearn: 0.6284436\ttotal: 48.5s\tremaining: 42.8s\n",
      "531:\tlearn: 0.6284200\ttotal: 48.5s\tremaining: 42.7s\n",
      "532:\tlearn: 0.6283861\ttotal: 48.7s\tremaining: 42.6s\n",
      "533:\tlearn: 0.6283642\ttotal: 48.8s\tremaining: 42.6s\n",
      "534:\tlearn: 0.6283418\ttotal: 48.9s\tremaining: 42.5s\n",
      "535:\tlearn: 0.6283126\ttotal: 49s\tremaining: 42.4s\n",
      "536:\tlearn: 0.6282787\ttotal: 49.1s\tremaining: 42.4s\n",
      "537:\tlearn: 0.6282588\ttotal: 49.2s\tremaining: 42.3s\n",
      "538:\tlearn: 0.6282081\ttotal: 49.3s\tremaining: 42.2s\n",
      "539:\tlearn: 0.6281657\ttotal: 49.4s\tremaining: 42.1s\n",
      "540:\tlearn: 0.6281365\ttotal: 49.5s\tremaining: 42s\n",
      "541:\tlearn: 0.6281076\ttotal: 49.6s\tremaining: 41.9s\n",
      "542:\tlearn: 0.6280656\ttotal: 49.7s\tremaining: 41.8s\n",
      "543:\tlearn: 0.6280367\ttotal: 49.7s\tremaining: 41.7s\n",
      "544:\tlearn: 0.6279994\ttotal: 49.8s\tremaining: 41.6s\n",
      "545:\tlearn: 0.6279689\ttotal: 49.9s\tremaining: 41.5s\n",
      "546:\tlearn: 0.6279354\ttotal: 50s\tremaining: 41.4s\n",
      "547:\tlearn: 0.6279165\ttotal: 50.1s\tremaining: 41.3s\n",
      "548:\tlearn: 0.6278945\ttotal: 50.2s\tremaining: 41.3s\n",
      "549:\tlearn: 0.6278701\ttotal: 50.4s\tremaining: 41.2s\n",
      "550:\tlearn: 0.6278398\ttotal: 50.5s\tremaining: 41.1s\n",
      "551:\tlearn: 0.6278085\ttotal: 50.6s\tremaining: 41.1s\n",
      "552:\tlearn: 0.6277755\ttotal: 50.7s\tremaining: 41s\n",
      "553:\tlearn: 0.6277437\ttotal: 50.8s\tremaining: 40.9s\n",
      "554:\tlearn: 0.6277254\ttotal: 50.9s\tremaining: 40.8s\n",
      "555:\tlearn: 0.6276952\ttotal: 51s\tremaining: 40.8s\n",
      "556:\tlearn: 0.6276604\ttotal: 51.1s\tremaining: 40.7s\n",
      "557:\tlearn: 0.6276375\ttotal: 51.2s\tremaining: 40.6s\n",
      "558:\tlearn: 0.6276121\ttotal: 51.3s\tremaining: 40.5s\n",
      "559:\tlearn: 0.6275807\ttotal: 51.5s\tremaining: 40.4s\n",
      "560:\tlearn: 0.6275583\ttotal: 51.5s\tremaining: 40.3s\n",
      "561:\tlearn: 0.6275238\ttotal: 51.6s\tremaining: 40.3s\n",
      "562:\tlearn: 0.6274997\ttotal: 51.7s\tremaining: 40.1s\n",
      "563:\tlearn: 0.6274723\ttotal: 51.8s\tremaining: 40.1s\n",
      "564:\tlearn: 0.6274501\ttotal: 51.9s\tremaining: 40s\n",
      "565:\tlearn: 0.6274151\ttotal: 52s\tremaining: 39.9s\n",
      "566:\tlearn: 0.6273912\ttotal: 52.1s\tremaining: 39.8s\n",
      "567:\tlearn: 0.6273611\ttotal: 52.2s\tremaining: 39.7s\n",
      "568:\tlearn: 0.6273286\ttotal: 52.3s\tremaining: 39.6s\n",
      "569:\tlearn: 0.6272911\ttotal: 52.4s\tremaining: 39.5s\n",
      "570:\tlearn: 0.6272651\ttotal: 52.5s\tremaining: 39.5s\n",
      "571:\tlearn: 0.6272371\ttotal: 52.6s\tremaining: 39.4s\n",
      "572:\tlearn: 0.6272090\ttotal: 52.7s\tremaining: 39.3s\n",
      "573:\tlearn: 0.6271819\ttotal: 52.8s\tremaining: 39.2s\n",
      "574:\tlearn: 0.6271595\ttotal: 52.8s\tremaining: 39.1s\n",
      "575:\tlearn: 0.6271233\ttotal: 52.9s\tremaining: 39s\n",
      "576:\tlearn: 0.6270987\ttotal: 53s\tremaining: 38.9s\n",
      "577:\tlearn: 0.6270580\ttotal: 53.2s\tremaining: 38.8s\n",
      "578:\tlearn: 0.6270226\ttotal: 53.2s\tremaining: 38.7s\n",
      "579:\tlearn: 0.6269980\ttotal: 53.3s\tremaining: 38.6s\n",
      "580:\tlearn: 0.6269649\ttotal: 53.4s\tremaining: 38.5s\n",
      "581:\tlearn: 0.6269364\ttotal: 53.5s\tremaining: 38.4s\n",
      "582:\tlearn: 0.6268970\ttotal: 53.6s\tremaining: 38.3s\n",
      "583:\tlearn: 0.6268614\ttotal: 53.7s\tremaining: 38.2s\n",
      "584:\tlearn: 0.6268309\ttotal: 53.8s\tremaining: 38.2s\n",
      "585:\tlearn: 0.6268037\ttotal: 53.9s\tremaining: 38.1s\n",
      "586:\tlearn: 0.6267728\ttotal: 54s\tremaining: 38s\n",
      "587:\tlearn: 0.6267415\ttotal: 54.2s\tremaining: 38s\n",
      "588:\tlearn: 0.6267140\ttotal: 54.3s\tremaining: 37.9s\n",
      "589:\tlearn: 0.6266812\ttotal: 54.4s\tremaining: 37.8s\n",
      "590:\tlearn: 0.6266509\ttotal: 54.4s\tremaining: 37.7s\n",
      "591:\tlearn: 0.6266228\ttotal: 54.6s\tremaining: 37.6s\n",
      "592:\tlearn: 0.6265945\ttotal: 54.7s\tremaining: 37.5s\n",
      "593:\tlearn: 0.6265738\ttotal: 54.8s\tremaining: 37.4s\n",
      "594:\tlearn: 0.6265571\ttotal: 54.8s\tremaining: 37.3s\n",
      "595:\tlearn: 0.6265305\ttotal: 54.9s\tremaining: 37.2s\n",
      "596:\tlearn: 0.6265060\ttotal: 55s\tremaining: 37.1s\n",
      "597:\tlearn: 0.6264694\ttotal: 55.1s\tremaining: 37s\n",
      "598:\tlearn: 0.6264446\ttotal: 55.2s\tremaining: 36.9s\n",
      "599:\tlearn: 0.6264176\ttotal: 55.2s\tremaining: 36.8s\n",
      "600:\tlearn: 0.6263913\ttotal: 55.3s\tremaining: 36.7s\n",
      "601:\tlearn: 0.6263588\ttotal: 55.4s\tremaining: 36.6s\n",
      "602:\tlearn: 0.6263239\ttotal: 55.5s\tremaining: 36.5s\n",
      "603:\tlearn: 0.6262889\ttotal: 55.6s\tremaining: 36.5s\n",
      "604:\tlearn: 0.6262645\ttotal: 55.7s\tremaining: 36.4s\n",
      "605:\tlearn: 0.6262330\ttotal: 55.8s\tremaining: 36.3s\n",
      "606:\tlearn: 0.6262024\ttotal: 55.9s\tremaining: 36.2s\n",
      "607:\tlearn: 0.6261805\ttotal: 56s\tremaining: 36.1s\n",
      "608:\tlearn: 0.6261517\ttotal: 56s\tremaining: 36s\n",
      "609:\tlearn: 0.6261244\ttotal: 56.2s\tremaining: 35.9s\n",
      "610:\tlearn: 0.6260765\ttotal: 56.3s\tremaining: 35.8s\n",
      "611:\tlearn: 0.6260423\ttotal: 56.3s\tremaining: 35.7s\n",
      "612:\tlearn: 0.6260267\ttotal: 56.4s\tremaining: 35.6s\n",
      "613:\tlearn: 0.6259936\ttotal: 56.5s\tremaining: 35.5s\n",
      "614:\tlearn: 0.6259654\ttotal: 56.6s\tremaining: 35.4s\n",
      "615:\tlearn: 0.6259314\ttotal: 56.7s\tremaining: 35.4s\n",
      "616:\tlearn: 0.6259127\ttotal: 56.8s\tremaining: 35.3s\n",
      "617:\tlearn: 0.6258801\ttotal: 56.9s\tremaining: 35.2s\n",
      "618:\tlearn: 0.6258437\ttotal: 57s\tremaining: 35.1s\n",
      "619:\tlearn: 0.6258079\ttotal: 57.1s\tremaining: 35s\n",
      "620:\tlearn: 0.6257667\ttotal: 57.2s\tremaining: 34.9s\n",
      "621:\tlearn: 0.6257370\ttotal: 57.3s\tremaining: 34.8s\n",
      "622:\tlearn: 0.6257048\ttotal: 57.3s\tremaining: 34.7s\n",
      "623:\tlearn: 0.6256873\ttotal: 57.5s\tremaining: 34.6s\n",
      "624:\tlearn: 0.6256550\ttotal: 57.6s\tremaining: 34.5s\n",
      "625:\tlearn: 0.6256297\ttotal: 57.7s\tremaining: 34.5s\n",
      "626:\tlearn: 0.6256017\ttotal: 57.7s\tremaining: 34.4s\n",
      "627:\tlearn: 0.6255770\ttotal: 57.8s\tremaining: 34.2s\n",
      "628:\tlearn: 0.6255433\ttotal: 57.9s\tremaining: 34.2s\n",
      "629:\tlearn: 0.6255165\ttotal: 58s\tremaining: 34.1s\n",
      "630:\tlearn: 0.6254881\ttotal: 58.1s\tremaining: 34s\n",
      "631:\tlearn: 0.6254550\ttotal: 58.2s\tremaining: 33.9s\n",
      "632:\tlearn: 0.6254206\ttotal: 58.3s\tremaining: 33.8s\n",
      "633:\tlearn: 0.6253899\ttotal: 58.4s\tremaining: 33.7s\n",
      "634:\tlearn: 0.6253585\ttotal: 58.5s\tremaining: 33.6s\n",
      "635:\tlearn: 0.6253316\ttotal: 58.6s\tremaining: 33.5s\n",
      "636:\tlearn: 0.6253022\ttotal: 58.7s\tremaining: 33.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637:\tlearn: 0.6252696\ttotal: 58.7s\tremaining: 33.3s\n",
      "638:\tlearn: 0.6252343\ttotal: 58.9s\tremaining: 33.3s\n",
      "639:\tlearn: 0.6252009\ttotal: 59s\tremaining: 33.2s\n",
      "640:\tlearn: 0.6251851\ttotal: 59.1s\tremaining: 33.1s\n",
      "641:\tlearn: 0.6251564\ttotal: 59.2s\tremaining: 33s\n",
      "642:\tlearn: 0.6251340\ttotal: 59.3s\tremaining: 32.9s\n",
      "643:\tlearn: 0.6250989\ttotal: 59.4s\tremaining: 32.8s\n",
      "644:\tlearn: 0.6250700\ttotal: 59.6s\tremaining: 32.8s\n",
      "645:\tlearn: 0.6250408\ttotal: 59.7s\tremaining: 32.7s\n",
      "646:\tlearn: 0.6250058\ttotal: 59.8s\tremaining: 32.6s\n",
      "647:\tlearn: 0.6249932\ttotal: 60s\tremaining: 32.6s\n",
      "648:\tlearn: 0.6249674\ttotal: 1m\tremaining: 32.5s\n",
      "649:\tlearn: 0.6249357\ttotal: 1m\tremaining: 32.4s\n",
      "650:\tlearn: 0.6249072\ttotal: 1m\tremaining: 32.3s\n",
      "651:\tlearn: 0.6248816\ttotal: 1m\tremaining: 32.2s\n",
      "652:\tlearn: 0.6248435\ttotal: 1m\tremaining: 32.1s\n",
      "653:\tlearn: 0.6248239\ttotal: 1m\tremaining: 32s\n",
      "654:\tlearn: 0.6247953\ttotal: 1m\tremaining: 32s\n",
      "655:\tlearn: 0.6247693\ttotal: 1m\tremaining: 31.9s\n",
      "656:\tlearn: 0.6247115\ttotal: 1m\tremaining: 31.8s\n",
      "657:\tlearn: 0.6246835\ttotal: 1m 1s\tremaining: 31.7s\n",
      "658:\tlearn: 0.6246516\ttotal: 1m 1s\tremaining: 31.7s\n",
      "659:\tlearn: 0.6246199\ttotal: 1m 1s\tremaining: 31.6s\n",
      "660:\tlearn: 0.6245950\ttotal: 1m 1s\tremaining: 31.5s\n",
      "661:\tlearn: 0.6245667\ttotal: 1m 1s\tremaining: 31.4s\n",
      "662:\tlearn: 0.6245385\ttotal: 1m 1s\tremaining: 31.3s\n",
      "663:\tlearn: 0.6245214\ttotal: 1m 1s\tremaining: 31.2s\n",
      "664:\tlearn: 0.6244851\ttotal: 1m 1s\tremaining: 31.1s\n",
      "665:\tlearn: 0.6244564\ttotal: 1m 1s\tremaining: 31s\n",
      "666:\tlearn: 0.6244347\ttotal: 1m 1s\tremaining: 30.9s\n",
      "667:\tlearn: 0.6244091\ttotal: 1m 2s\tremaining: 30.9s\n",
      "668:\tlearn: 0.6243748\ttotal: 1m 2s\tremaining: 30.8s\n",
      "669:\tlearn: 0.6243511\ttotal: 1m 2s\tremaining: 30.7s\n",
      "670:\tlearn: 0.6243116\ttotal: 1m 2s\tremaining: 30.6s\n",
      "671:\tlearn: 0.6242838\ttotal: 1m 2s\tremaining: 30.5s\n",
      "672:\tlearn: 0.6242580\ttotal: 1m 2s\tremaining: 30.4s\n",
      "673:\tlearn: 0.6242278\ttotal: 1m 2s\tremaining: 30.3s\n",
      "674:\tlearn: 0.6241959\ttotal: 1m 2s\tremaining: 30.2s\n",
      "675:\tlearn: 0.6241718\ttotal: 1m 2s\tremaining: 30.1s\n",
      "676:\tlearn: 0.6241422\ttotal: 1m 2s\tremaining: 30s\n",
      "677:\tlearn: 0.6241276\ttotal: 1m 3s\tremaining: 29.9s\n",
      "678:\tlearn: 0.6241034\ttotal: 1m 3s\tremaining: 29.9s\n",
      "679:\tlearn: 0.6240732\ttotal: 1m 3s\tremaining: 29.8s\n",
      "680:\tlearn: 0.6240479\ttotal: 1m 3s\tremaining: 29.7s\n",
      "681:\tlearn: 0.6240242\ttotal: 1m 3s\tremaining: 29.6s\n",
      "682:\tlearn: 0.6239890\ttotal: 1m 3s\tremaining: 29.5s\n",
      "683:\tlearn: 0.6239734\ttotal: 1m 3s\tremaining: 29.4s\n",
      "684:\tlearn: 0.6239486\ttotal: 1m 3s\tremaining: 29.3s\n",
      "685:\tlearn: 0.6239162\ttotal: 1m 3s\tremaining: 29.2s\n",
      "686:\tlearn: 0.6238877\ttotal: 1m 3s\tremaining: 29.1s\n",
      "687:\tlearn: 0.6238574\ttotal: 1m 4s\tremaining: 29.1s\n",
      "688:\tlearn: 0.6238313\ttotal: 1m 4s\tremaining: 29s\n",
      "689:\tlearn: 0.6238016\ttotal: 1m 4s\tremaining: 28.9s\n",
      "690:\tlearn: 0.6237780\ttotal: 1m 4s\tremaining: 28.8s\n",
      "691:\tlearn: 0.6237530\ttotal: 1m 4s\tremaining: 28.7s\n",
      "692:\tlearn: 0.6237294\ttotal: 1m 4s\tremaining: 28.6s\n",
      "693:\tlearn: 0.6236992\ttotal: 1m 4s\tremaining: 28.6s\n",
      "694:\tlearn: 0.6236691\ttotal: 1m 4s\tremaining: 28.5s\n",
      "695:\tlearn: 0.6236398\ttotal: 1m 4s\tremaining: 28.4s\n",
      "696:\tlearn: 0.6236139\ttotal: 1m 5s\tremaining: 28.3s\n",
      "697:\tlearn: 0.6235977\ttotal: 1m 5s\tremaining: 28.2s\n",
      "698:\tlearn: 0.6235725\ttotal: 1m 5s\tremaining: 28.1s\n",
      "699:\tlearn: 0.6235436\ttotal: 1m 5s\tremaining: 28s\n",
      "700:\tlearn: 0.6235141\ttotal: 1m 5s\tremaining: 27.9s\n",
      "701:\tlearn: 0.6234770\ttotal: 1m 5s\tremaining: 27.8s\n",
      "702:\tlearn: 0.6234502\ttotal: 1m 5s\tremaining: 27.7s\n",
      "703:\tlearn: 0.6234261\ttotal: 1m 5s\tremaining: 27.6s\n",
      "704:\tlearn: 0.6234139\ttotal: 1m 5s\tremaining: 27.5s\n",
      "705:\tlearn: 0.6233977\ttotal: 1m 5s\tremaining: 27.5s\n",
      "706:\tlearn: 0.6233768\ttotal: 1m 6s\tremaining: 27.4s\n",
      "707:\tlearn: 0.6233574\ttotal: 1m 6s\tremaining: 27.3s\n",
      "708:\tlearn: 0.6233236\ttotal: 1m 6s\tremaining: 27.2s\n",
      "709:\tlearn: 0.6232951\ttotal: 1m 6s\tremaining: 27.1s\n",
      "710:\tlearn: 0.6232567\ttotal: 1m 6s\tremaining: 27s\n",
      "711:\tlearn: 0.6232336\ttotal: 1m 6s\tremaining: 26.9s\n",
      "712:\tlearn: 0.6231989\ttotal: 1m 6s\tremaining: 26.8s\n",
      "713:\tlearn: 0.6231778\ttotal: 1m 6s\tremaining: 26.7s\n",
      "714:\tlearn: 0.6231493\ttotal: 1m 6s\tremaining: 26.6s\n",
      "715:\tlearn: 0.6231204\ttotal: 1m 6s\tremaining: 26.5s\n",
      "716:\tlearn: 0.6230903\ttotal: 1m 6s\tremaining: 26.4s\n",
      "717:\tlearn: 0.6230623\ttotal: 1m 7s\tremaining: 26.3s\n",
      "718:\tlearn: 0.6230350\ttotal: 1m 7s\tremaining: 26.2s\n",
      "719:\tlearn: 0.6230152\ttotal: 1m 7s\tremaining: 26.1s\n",
      "720:\tlearn: 0.6229840\ttotal: 1m 7s\tremaining: 26.1s\n",
      "721:\tlearn: 0.6229517\ttotal: 1m 7s\tremaining: 26s\n",
      "722:\tlearn: 0.6229280\ttotal: 1m 7s\tremaining: 25.9s\n",
      "723:\tlearn: 0.6229108\ttotal: 1m 7s\tremaining: 25.8s\n",
      "724:\tlearn: 0.6228838\ttotal: 1m 7s\tremaining: 25.7s\n",
      "725:\tlearn: 0.6228684\ttotal: 1m 7s\tremaining: 25.6s\n",
      "726:\tlearn: 0.6228344\ttotal: 1m 7s\tremaining: 25.5s\n",
      "727:\tlearn: 0.6228047\ttotal: 1m 8s\tremaining: 25.4s\n",
      "728:\tlearn: 0.6227750\ttotal: 1m 8s\tremaining: 25.3s\n",
      "729:\tlearn: 0.6227533\ttotal: 1m 8s\tremaining: 25.3s\n",
      "730:\tlearn: 0.6227218\ttotal: 1m 8s\tremaining: 25.2s\n",
      "731:\tlearn: 0.6227025\ttotal: 1m 8s\tremaining: 25.1s\n",
      "732:\tlearn: 0.6226724\ttotal: 1m 8s\tremaining: 25s\n",
      "733:\tlearn: 0.6226394\ttotal: 1m 8s\tremaining: 24.9s\n",
      "734:\tlearn: 0.6226158\ttotal: 1m 8s\tremaining: 24.8s\n",
      "735:\tlearn: 0.6225993\ttotal: 1m 8s\tremaining: 24.7s\n",
      "736:\tlearn: 0.6225748\ttotal: 1m 9s\tremaining: 24.6s\n",
      "737:\tlearn: 0.6225493\ttotal: 1m 9s\tremaining: 24.5s\n",
      "738:\tlearn: 0.6225272\ttotal: 1m 9s\tremaining: 24.4s\n",
      "739:\tlearn: 0.6225061\ttotal: 1m 9s\tremaining: 24.3s\n",
      "740:\tlearn: 0.6224785\ttotal: 1m 9s\tremaining: 24.3s\n",
      "741:\tlearn: 0.6224487\ttotal: 1m 9s\tremaining: 24.2s\n",
      "742:\tlearn: 0.6224222\ttotal: 1m 9s\tremaining: 24.1s\n",
      "743:\tlearn: 0.6223903\ttotal: 1m 9s\tremaining: 24s\n",
      "744:\tlearn: 0.6223712\ttotal: 1m 9s\tremaining: 23.9s\n",
      "745:\tlearn: 0.6223407\ttotal: 1m 9s\tremaining: 23.8s\n",
      "746:\tlearn: 0.6223120\ttotal: 1m 9s\tremaining: 23.7s\n",
      "747:\tlearn: 0.6222909\ttotal: 1m 10s\tremaining: 23.6s\n",
      "748:\tlearn: 0.6222662\ttotal: 1m 10s\tremaining: 23.5s\n",
      "749:\tlearn: 0.6222467\ttotal: 1m 10s\tremaining: 23.4s\n",
      "750:\tlearn: 0.6222402\ttotal: 1m 10s\tremaining: 23.3s\n",
      "751:\tlearn: 0.6222176\ttotal: 1m 10s\tremaining: 23.3s\n",
      "752:\tlearn: 0.6221873\ttotal: 1m 10s\tremaining: 23.2s\n",
      "753:\tlearn: 0.6221520\ttotal: 1m 10s\tremaining: 23.1s\n",
      "754:\tlearn: 0.6221226\ttotal: 1m 10s\tremaining: 23s\n",
      "755:\tlearn: 0.6220897\ttotal: 1m 10s\tremaining: 22.9s\n",
      "756:\tlearn: 0.6220701\ttotal: 1m 11s\tremaining: 22.8s\n",
      "757:\tlearn: 0.6220430\ttotal: 1m 11s\tremaining: 22.7s\n",
      "758:\tlearn: 0.6220223\ttotal: 1m 11s\tremaining: 22.6s\n",
      "759:\tlearn: 0.6219911\ttotal: 1m 11s\tremaining: 22.5s\n",
      "760:\tlearn: 0.6219638\ttotal: 1m 11s\tremaining: 22.5s\n",
      "761:\tlearn: 0.6219401\ttotal: 1m 11s\tremaining: 22.4s\n",
      "762:\tlearn: 0.6219078\ttotal: 1m 11s\tremaining: 22.3s\n",
      "763:\tlearn: 0.6218739\ttotal: 1m 11s\tremaining: 22.2s\n",
      "764:\tlearn: 0.6218471\ttotal: 1m 11s\tremaining: 22.1s\n",
      "765:\tlearn: 0.6218262\ttotal: 1m 12s\tremaining: 22s\n",
      "766:\tlearn: 0.6217982\ttotal: 1m 12s\tremaining: 21.9s\n",
      "767:\tlearn: 0.6217698\ttotal: 1m 12s\tremaining: 21.8s\n",
      "768:\tlearn: 0.6217465\ttotal: 1m 12s\tremaining: 21.7s\n",
      "769:\tlearn: 0.6217158\ttotal: 1m 12s\tremaining: 21.6s\n",
      "770:\tlearn: 0.6217020\ttotal: 1m 12s\tremaining: 21.5s\n",
      "771:\tlearn: 0.6216848\ttotal: 1m 12s\tremaining: 21.5s\n",
      "772:\tlearn: 0.6216604\ttotal: 1m 12s\tremaining: 21.4s\n",
      "773:\tlearn: 0.6216357\ttotal: 1m 12s\tremaining: 21.3s\n",
      "774:\tlearn: 0.6216076\ttotal: 1m 12s\tremaining: 21.2s\n",
      "775:\tlearn: 0.6215759\ttotal: 1m 13s\tremaining: 21.1s\n",
      "776:\tlearn: 0.6215526\ttotal: 1m 13s\tremaining: 21s\n",
      "777:\tlearn: 0.6215366\ttotal: 1m 13s\tremaining: 20.9s\n",
      "778:\tlearn: 0.6215145\ttotal: 1m 13s\tremaining: 20.8s\n",
      "779:\tlearn: 0.6214878\ttotal: 1m 13s\tremaining: 20.7s\n",
      "780:\tlearn: 0.6214588\ttotal: 1m 13s\tremaining: 20.6s\n",
      "781:\tlearn: 0.6214219\ttotal: 1m 13s\tremaining: 20.5s\n",
      "782:\tlearn: 0.6213934\ttotal: 1m 13s\tremaining: 20.4s\n",
      "783:\tlearn: 0.6213697\ttotal: 1m 13s\tremaining: 20.3s\n",
      "784:\tlearn: 0.6213470\ttotal: 1m 13s\tremaining: 20.3s\n",
      "785:\tlearn: 0.6213194\ttotal: 1m 14s\tremaining: 20.2s\n",
      "786:\tlearn: 0.6212871\ttotal: 1m 14s\tremaining: 20.1s\n",
      "787:\tlearn: 0.6212745\ttotal: 1m 14s\tremaining: 20s\n",
      "788:\tlearn: 0.6212485\ttotal: 1m 14s\tremaining: 19.9s\n",
      "789:\tlearn: 0.6212286\ttotal: 1m 14s\tremaining: 19.8s\n",
      "790:\tlearn: 0.6211935\ttotal: 1m 14s\tremaining: 19.7s\n",
      "791:\tlearn: 0.6211642\ttotal: 1m 14s\tremaining: 19.6s\n",
      "792:\tlearn: 0.6211372\ttotal: 1m 14s\tremaining: 19.5s\n",
      "793:\tlearn: 0.6211078\ttotal: 1m 14s\tremaining: 19.4s\n",
      "794:\tlearn: 0.6210774\ttotal: 1m 15s\tremaining: 19.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "795:\tlearn: 0.6210504\ttotal: 1m 15s\tremaining: 19.2s\n",
      "796:\tlearn: 0.6210287\ttotal: 1m 15s\tremaining: 19.1s\n",
      "797:\tlearn: 0.6210063\ttotal: 1m 15s\tremaining: 19.1s\n",
      "798:\tlearn: 0.6209860\ttotal: 1m 15s\tremaining: 19s\n",
      "799:\tlearn: 0.6209625\ttotal: 1m 15s\tremaining: 18.9s\n",
      "800:\tlearn: 0.6209368\ttotal: 1m 15s\tremaining: 18.8s\n",
      "801:\tlearn: 0.6209147\ttotal: 1m 15s\tremaining: 18.7s\n",
      "802:\tlearn: 0.6208905\ttotal: 1m 15s\tremaining: 18.6s\n",
      "803:\tlearn: 0.6208525\ttotal: 1m 15s\tremaining: 18.5s\n",
      "804:\tlearn: 0.6208198\ttotal: 1m 15s\tremaining: 18.4s\n",
      "805:\tlearn: 0.6207966\ttotal: 1m 16s\tremaining: 18.3s\n",
      "806:\tlearn: 0.6207763\ttotal: 1m 16s\tremaining: 18.2s\n",
      "807:\tlearn: 0.6207460\ttotal: 1m 16s\tremaining: 18.1s\n",
      "808:\tlearn: 0.6207231\ttotal: 1m 16s\tremaining: 18s\n",
      "809:\tlearn: 0.6206963\ttotal: 1m 16s\tremaining: 17.9s\n",
      "810:\tlearn: 0.6206734\ttotal: 1m 16s\tremaining: 17.9s\n",
      "811:\tlearn: 0.6206463\ttotal: 1m 16s\tremaining: 17.8s\n",
      "812:\tlearn: 0.6206238\ttotal: 1m 16s\tremaining: 17.7s\n",
      "813:\tlearn: 0.6206006\ttotal: 1m 17s\tremaining: 17.6s\n",
      "814:\tlearn: 0.6205709\ttotal: 1m 17s\tremaining: 17.5s\n",
      "815:\tlearn: 0.6205475\ttotal: 1m 17s\tremaining: 17.4s\n",
      "816:\tlearn: 0.6205201\ttotal: 1m 17s\tremaining: 17.3s\n",
      "817:\tlearn: 0.6204982\ttotal: 1m 17s\tremaining: 17.2s\n",
      "818:\tlearn: 0.6204731\ttotal: 1m 17s\tremaining: 17.1s\n",
      "819:\tlearn: 0.6204515\ttotal: 1m 17s\tremaining: 17.1s\n",
      "820:\tlearn: 0.6204235\ttotal: 1m 17s\tremaining: 17s\n",
      "821:\tlearn: 0.6204032\ttotal: 1m 17s\tremaining: 16.9s\n",
      "822:\tlearn: 0.6203803\ttotal: 1m 17s\tremaining: 16.8s\n",
      "823:\tlearn: 0.6203573\ttotal: 1m 18s\tremaining: 16.7s\n",
      "824:\tlearn: 0.6203410\ttotal: 1m 18s\tremaining: 16.6s\n",
      "825:\tlearn: 0.6203077\ttotal: 1m 18s\tremaining: 16.5s\n",
      "826:\tlearn: 0.6202883\ttotal: 1m 18s\tremaining: 16.4s\n",
      "827:\tlearn: 0.6202622\ttotal: 1m 18s\tremaining: 16.3s\n",
      "828:\tlearn: 0.6202427\ttotal: 1m 18s\tremaining: 16.2s\n",
      "829:\tlearn: 0.6202297\ttotal: 1m 18s\tremaining: 16.1s\n",
      "830:\tlearn: 0.6202027\ttotal: 1m 18s\tremaining: 16s\n",
      "831:\tlearn: 0.6201790\ttotal: 1m 18s\tremaining: 15.9s\n",
      "832:\tlearn: 0.6201477\ttotal: 1m 18s\tremaining: 15.8s\n",
      "833:\tlearn: 0.6201273\ttotal: 1m 19s\tremaining: 15.7s\n",
      "834:\tlearn: 0.6201153\ttotal: 1m 19s\tremaining: 15.6s\n",
      "835:\tlearn: 0.6200876\ttotal: 1m 19s\tremaining: 15.6s\n",
      "836:\tlearn: 0.6200730\ttotal: 1m 19s\tremaining: 15.5s\n",
      "837:\tlearn: 0.6200469\ttotal: 1m 19s\tremaining: 15.4s\n",
      "838:\tlearn: 0.6200182\ttotal: 1m 19s\tremaining: 15.3s\n",
      "839:\tlearn: 0.6199951\ttotal: 1m 19s\tremaining: 15.2s\n",
      "840:\tlearn: 0.6199804\ttotal: 1m 19s\tremaining: 15.1s\n",
      "841:\tlearn: 0.6199535\ttotal: 1m 19s\tremaining: 15s\n",
      "842:\tlearn: 0.6199330\ttotal: 1m 20s\tremaining: 14.9s\n",
      "843:\tlearn: 0.6199125\ttotal: 1m 20s\tremaining: 14.8s\n",
      "844:\tlearn: 0.6198889\ttotal: 1m 20s\tremaining: 14.7s\n",
      "845:\tlearn: 0.6198547\ttotal: 1m 20s\tremaining: 14.6s\n",
      "846:\tlearn: 0.6198292\ttotal: 1m 20s\tremaining: 14.5s\n",
      "847:\tlearn: 0.6198107\ttotal: 1m 20s\tremaining: 14.4s\n",
      "848:\tlearn: 0.6197927\ttotal: 1m 20s\tremaining: 14.4s\n",
      "849:\tlearn: 0.6197765\ttotal: 1m 20s\tremaining: 14.3s\n",
      "850:\tlearn: 0.6197515\ttotal: 1m 20s\tremaining: 14.2s\n",
      "851:\tlearn: 0.6197246\ttotal: 1m 21s\tremaining: 14.1s\n",
      "852:\tlearn: 0.6196994\ttotal: 1m 21s\tremaining: 14s\n",
      "853:\tlearn: 0.6196839\ttotal: 1m 21s\tremaining: 13.9s\n",
      "854:\tlearn: 0.6196612\ttotal: 1m 21s\tremaining: 13.8s\n",
      "855:\tlearn: 0.6196340\ttotal: 1m 21s\tremaining: 13.7s\n",
      "856:\tlearn: 0.6196113\ttotal: 1m 21s\tremaining: 13.6s\n",
      "857:\tlearn: 0.6195871\ttotal: 1m 21s\tremaining: 13.5s\n",
      "858:\tlearn: 0.6195652\ttotal: 1m 21s\tremaining: 13.4s\n",
      "859:\tlearn: 0.6195387\ttotal: 1m 21s\tremaining: 13.3s\n",
      "860:\tlearn: 0.6195052\ttotal: 1m 21s\tremaining: 13.2s\n",
      "861:\tlearn: 0.6194744\ttotal: 1m 22s\tremaining: 13.1s\n",
      "862:\tlearn: 0.6194550\ttotal: 1m 22s\tremaining: 13s\n",
      "863:\tlearn: 0.6194373\ttotal: 1m 22s\tremaining: 12.9s\n",
      "864:\tlearn: 0.6194179\ttotal: 1m 22s\tremaining: 12.9s\n",
      "865:\tlearn: 0.6193981\ttotal: 1m 22s\tremaining: 12.8s\n",
      "866:\tlearn: 0.6193763\ttotal: 1m 22s\tremaining: 12.7s\n",
      "867:\tlearn: 0.6193503\ttotal: 1m 22s\tremaining: 12.6s\n",
      "868:\tlearn: 0.6193276\ttotal: 1m 22s\tremaining: 12.5s\n",
      "869:\tlearn: 0.6193001\ttotal: 1m 22s\tremaining: 12.4s\n",
      "870:\tlearn: 0.6192791\ttotal: 1m 22s\tremaining: 12.3s\n",
      "871:\tlearn: 0.6192578\ttotal: 1m 23s\tremaining: 12.2s\n",
      "872:\tlearn: 0.6192289\ttotal: 1m 23s\tremaining: 12.1s\n",
      "873:\tlearn: 0.6192099\ttotal: 1m 23s\tremaining: 12s\n",
      "874:\tlearn: 0.6191901\ttotal: 1m 23s\tremaining: 11.9s\n",
      "875:\tlearn: 0.6191722\ttotal: 1m 23s\tremaining: 11.8s\n",
      "876:\tlearn: 0.6191571\ttotal: 1m 23s\tremaining: 11.7s\n",
      "877:\tlearn: 0.6191316\ttotal: 1m 23s\tremaining: 11.7s\n",
      "878:\tlearn: 0.6191135\ttotal: 1m 23s\tremaining: 11.6s\n",
      "879:\tlearn: 0.6190794\ttotal: 1m 24s\tremaining: 11.5s\n",
      "880:\tlearn: 0.6190458\ttotal: 1m 24s\tremaining: 11.4s\n",
      "881:\tlearn: 0.6190120\ttotal: 1m 24s\tremaining: 11.3s\n",
      "882:\tlearn: 0.6189829\ttotal: 1m 24s\tremaining: 11.2s\n",
      "883:\tlearn: 0.6189599\ttotal: 1m 24s\tremaining: 11.1s\n",
      "884:\tlearn: 0.6189271\ttotal: 1m 24s\tremaining: 11s\n",
      "885:\tlearn: 0.6189208\ttotal: 1m 24s\tremaining: 10.9s\n",
      "886:\tlearn: 0.6188966\ttotal: 1m 24s\tremaining: 10.8s\n",
      "887:\tlearn: 0.6188742\ttotal: 1m 24s\tremaining: 10.7s\n",
      "888:\tlearn: 0.6188429\ttotal: 1m 24s\tremaining: 10.6s\n",
      "889:\tlearn: 0.6188177\ttotal: 1m 25s\tremaining: 10.5s\n",
      "890:\tlearn: 0.6187991\ttotal: 1m 25s\tremaining: 10.4s\n",
      "891:\tlearn: 0.6187739\ttotal: 1m 25s\tremaining: 10.3s\n",
      "892:\tlearn: 0.6187490\ttotal: 1m 25s\tremaining: 10.2s\n",
      "893:\tlearn: 0.6187365\ttotal: 1m 25s\tremaining: 10.1s\n",
      "894:\tlearn: 0.6187206\ttotal: 1m 25s\tremaining: 10s\n",
      "895:\tlearn: 0.6186964\ttotal: 1m 25s\tremaining: 9.95s\n",
      "896:\tlearn: 0.6186748\ttotal: 1m 25s\tremaining: 9.85s\n",
      "897:\tlearn: 0.6186617\ttotal: 1m 25s\tremaining: 9.76s\n",
      "898:\tlearn: 0.6186399\ttotal: 1m 26s\tremaining: 9.67s\n",
      "899:\tlearn: 0.6186197\ttotal: 1m 26s\tremaining: 9.57s\n",
      "900:\tlearn: 0.6185943\ttotal: 1m 26s\tremaining: 9.48s\n",
      "901:\tlearn: 0.6185760\ttotal: 1m 26s\tremaining: 9.38s\n",
      "902:\tlearn: 0.6185580\ttotal: 1m 26s\tremaining: 9.29s\n",
      "903:\tlearn: 0.6185373\ttotal: 1m 26s\tremaining: 9.19s\n",
      "904:\tlearn: 0.6185186\ttotal: 1m 26s\tremaining: 9.1s\n",
      "905:\tlearn: 0.6184903\ttotal: 1m 26s\tremaining: 9s\n",
      "906:\tlearn: 0.6184660\ttotal: 1m 26s\tremaining: 8.9s\n",
      "907:\tlearn: 0.6184346\ttotal: 1m 26s\tremaining: 8.81s\n",
      "908:\tlearn: 0.6184141\ttotal: 1m 27s\tremaining: 8.72s\n",
      "909:\tlearn: 0.6183923\ttotal: 1m 27s\tremaining: 8.62s\n",
      "910:\tlearn: 0.6183670\ttotal: 1m 27s\tremaining: 8.53s\n",
      "911:\tlearn: 0.6183472\ttotal: 1m 27s\tremaining: 8.43s\n",
      "912:\tlearn: 0.6183342\ttotal: 1m 27s\tremaining: 8.34s\n",
      "913:\tlearn: 0.6183011\ttotal: 1m 27s\tremaining: 8.24s\n",
      "914:\tlearn: 0.6182781\ttotal: 1m 27s\tremaining: 8.15s\n",
      "915:\tlearn: 0.6182562\ttotal: 1m 27s\tremaining: 8.05s\n",
      "916:\tlearn: 0.6182331\ttotal: 1m 27s\tremaining: 7.96s\n",
      "917:\tlearn: 0.6182104\ttotal: 1m 28s\tremaining: 7.86s\n",
      "918:\tlearn: 0.6181822\ttotal: 1m 28s\tremaining: 7.77s\n",
      "919:\tlearn: 0.6181547\ttotal: 1m 28s\tremaining: 7.67s\n",
      "920:\tlearn: 0.6181308\ttotal: 1m 28s\tremaining: 7.58s\n",
      "921:\tlearn: 0.6181009\ttotal: 1m 28s\tremaining: 7.48s\n",
      "922:\tlearn: 0.6180738\ttotal: 1m 28s\tremaining: 7.39s\n",
      "923:\tlearn: 0.6180465\ttotal: 1m 28s\tremaining: 7.29s\n",
      "924:\tlearn: 0.6180266\ttotal: 1m 28s\tremaining: 7.2s\n",
      "925:\tlearn: 0.6180088\ttotal: 1m 28s\tremaining: 7.11s\n",
      "926:\tlearn: 0.6179899\ttotal: 1m 29s\tremaining: 7.01s\n",
      "927:\tlearn: 0.6179720\ttotal: 1m 29s\tremaining: 6.91s\n",
      "928:\tlearn: 0.6179378\ttotal: 1m 29s\tremaining: 6.82s\n",
      "929:\tlearn: 0.6179203\ttotal: 1m 29s\tremaining: 6.72s\n",
      "930:\tlearn: 0.6179001\ttotal: 1m 29s\tremaining: 6.63s\n",
      "931:\tlearn: 0.6178780\ttotal: 1m 29s\tremaining: 6.53s\n",
      "932:\tlearn: 0.6178527\ttotal: 1m 29s\tremaining: 6.44s\n",
      "933:\tlearn: 0.6178389\ttotal: 1m 29s\tremaining: 6.34s\n",
      "934:\tlearn: 0.6178151\ttotal: 1m 29s\tremaining: 6.25s\n",
      "935:\tlearn: 0.6177969\ttotal: 1m 29s\tremaining: 6.15s\n",
      "936:\tlearn: 0.6177721\ttotal: 1m 30s\tremaining: 6.05s\n",
      "937:\tlearn: 0.6177465\ttotal: 1m 30s\tremaining: 5.96s\n",
      "938:\tlearn: 0.6177160\ttotal: 1m 30s\tremaining: 5.86s\n",
      "939:\tlearn: 0.6176870\ttotal: 1m 30s\tremaining: 5.76s\n",
      "940:\tlearn: 0.6176727\ttotal: 1m 30s\tremaining: 5.67s\n",
      "941:\tlearn: 0.6176465\ttotal: 1m 30s\tremaining: 5.57s\n",
      "942:\tlearn: 0.6176305\ttotal: 1m 30s\tremaining: 5.48s\n",
      "943:\tlearn: 0.6176036\ttotal: 1m 30s\tremaining: 5.38s\n",
      "944:\tlearn: 0.6175667\ttotal: 1m 30s\tremaining: 5.28s\n",
      "945:\tlearn: 0.6175432\ttotal: 1m 30s\tremaining: 5.19s\n",
      "946:\tlearn: 0.6175229\ttotal: 1m 31s\tremaining: 5.09s\n",
      "947:\tlearn: 0.6175014\ttotal: 1m 31s\tremaining: 5s\n",
      "948:\tlearn: 0.6174729\ttotal: 1m 31s\tremaining: 4.9s\n",
      "949:\tlearn: 0.6174594\ttotal: 1m 31s\tremaining: 4.81s\n",
      "950:\tlearn: 0.6174366\ttotal: 1m 31s\tremaining: 4.71s\n",
      "951:\tlearn: 0.6174070\ttotal: 1m 31s\tremaining: 4.61s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952:\tlearn: 0.6173798\ttotal: 1m 31s\tremaining: 4.52s\n",
      "953:\tlearn: 0.6173375\ttotal: 1m 31s\tremaining: 4.42s\n",
      "954:\tlearn: 0.6173156\ttotal: 1m 31s\tremaining: 4.33s\n",
      "955:\tlearn: 0.6172910\ttotal: 1m 31s\tremaining: 4.23s\n",
      "956:\tlearn: 0.6172705\ttotal: 1m 31s\tremaining: 4.13s\n",
      "957:\tlearn: 0.6172343\ttotal: 1m 32s\tremaining: 4.04s\n",
      "958:\tlearn: 0.6172179\ttotal: 1m 32s\tremaining: 3.94s\n",
      "959:\tlearn: 0.6172004\ttotal: 1m 32s\tremaining: 3.84s\n",
      "960:\tlearn: 0.6171791\ttotal: 1m 32s\tremaining: 3.75s\n",
      "961:\tlearn: 0.6171534\ttotal: 1m 32s\tremaining: 3.65s\n",
      "962:\tlearn: 0.6171320\ttotal: 1m 32s\tremaining: 3.55s\n",
      "963:\tlearn: 0.6171054\ttotal: 1m 32s\tremaining: 3.46s\n",
      "964:\tlearn: 0.6170815\ttotal: 1m 32s\tremaining: 3.36s\n",
      "965:\tlearn: 0.6170576\ttotal: 1m 32s\tremaining: 3.27s\n",
      "966:\tlearn: 0.6170316\ttotal: 1m 32s\tremaining: 3.17s\n",
      "967:\tlearn: 0.6170085\ttotal: 1m 32s\tremaining: 3.07s\n",
      "968:\tlearn: 0.6169832\ttotal: 1m 33s\tremaining: 2.98s\n",
      "969:\tlearn: 0.6169657\ttotal: 1m 33s\tremaining: 2.88s\n",
      "970:\tlearn: 0.6169489\ttotal: 1m 33s\tremaining: 2.78s\n",
      "971:\tlearn: 0.6169268\ttotal: 1m 33s\tremaining: 2.69s\n",
      "972:\tlearn: 0.6169025\ttotal: 1m 33s\tremaining: 2.59s\n",
      "973:\tlearn: 0.6168807\ttotal: 1m 33s\tremaining: 2.5s\n",
      "974:\tlearn: 0.6168555\ttotal: 1m 33s\tremaining: 2.4s\n",
      "975:\tlearn: 0.6168287\ttotal: 1m 33s\tremaining: 2.3s\n",
      "976:\tlearn: 0.6167998\ttotal: 1m 33s\tremaining: 2.21s\n",
      "977:\tlearn: 0.6167792\ttotal: 1m 33s\tremaining: 2.11s\n",
      "978:\tlearn: 0.6167634\ttotal: 1m 33s\tremaining: 2.02s\n",
      "979:\tlearn: 0.6167321\ttotal: 1m 34s\tremaining: 1.92s\n",
      "980:\tlearn: 0.6167071\ttotal: 1m 34s\tremaining: 1.82s\n",
      "981:\tlearn: 0.6166781\ttotal: 1m 34s\tremaining: 1.73s\n",
      "982:\tlearn: 0.6166545\ttotal: 1m 34s\tremaining: 1.63s\n",
      "983:\tlearn: 0.6166346\ttotal: 1m 34s\tremaining: 1.54s\n",
      "984:\tlearn: 0.6166096\ttotal: 1m 34s\tremaining: 1.44s\n",
      "985:\tlearn: 0.6165810\ttotal: 1m 34s\tremaining: 1.35s\n",
      "986:\tlearn: 0.6165575\ttotal: 1m 34s\tremaining: 1.25s\n",
      "987:\tlearn: 0.6165379\ttotal: 1m 35s\tremaining: 1.15s\n",
      "988:\tlearn: 0.6165154\ttotal: 1m 35s\tremaining: 1.06s\n",
      "989:\tlearn: 0.6165033\ttotal: 1m 35s\tremaining: 962ms\n",
      "990:\tlearn: 0.6164806\ttotal: 1m 35s\tremaining: 865ms\n",
      "991:\tlearn: 0.6164515\ttotal: 1m 35s\tremaining: 769ms\n",
      "992:\tlearn: 0.6164237\ttotal: 1m 35s\tremaining: 673ms\n",
      "993:\tlearn: 0.6163924\ttotal: 1m 35s\tremaining: 577ms\n",
      "994:\tlearn: 0.6163783\ttotal: 1m 35s\tremaining: 481ms\n",
      "995:\tlearn: 0.6163654\ttotal: 1m 35s\tremaining: 385ms\n",
      "996:\tlearn: 0.6163403\ttotal: 1m 35s\tremaining: 289ms\n",
      "997:\tlearn: 0.6163231\ttotal: 1m 35s\tremaining: 192ms\n",
      "998:\tlearn: 0.6162982\ttotal: 1m 36s\tremaining: 96.2ms\n",
      "999:\tlearn: 0.6162772\ttotal: 1m 36s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>shap_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>DDD_sum</td>\n",
       "      <td>0.185835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>contents_attribute_j_1</td>\n",
       "      <td>0.087212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>contents_attribute_a</td>\n",
       "      <td>0.077718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>contents_open_hour</td>\n",
       "      <td>0.071548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>D_H_1_sum</td>\n",
       "      <td>0.062908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>person_prefer_h_2_attribute_h_l_contents_attri...</td>\n",
       "      <td>0.00026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>person_prefer_h_3_attribute_h_m_contents_attri...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>person_prefer_d_3_attribute_d_d_contents_attri...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d_s_match_yn</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>person_prefer_d_2_contents_attribute_d</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          column_name shap_importance\n",
       "99                                            DDD_sum        0.185835\n",
       "19                             contents_attribute_j_1        0.087212\n",
       "18                               contents_attribute_a        0.077718\n",
       "30                                 contents_open_hour        0.071548\n",
       "90                                          D_H_1_sum        0.062908\n",
       "..                                                ...             ...\n",
       "76  person_prefer_h_2_attribute_h_l_contents_attri...         0.00026\n",
       "78  person_prefer_h_3_attribute_h_m_contents_attri...             0.0\n",
       "70  person_prefer_d_3_attribute_d_d_contents_attri...             0.0\n",
       "2                                        d_s_match_yn             0.0\n",
       "64             person_prefer_d_2_contents_attribute_d             0.0\n",
       "\n",
       "[123 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shap\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import kerastuner as kt\n",
    "print(tf.__version__)\n",
    "\n",
    "# DF, based on which importance is checked\n",
    "X_importance = x_train.drop('a_assemble', axis=1)\n",
    "#Explain model predictions using shap library:\n",
    "model = CatBoostClassifier(random_state=0).fit(x_train.drop('a_assemble', axis=1), train.target)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_importance)\n",
    "shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "importance_df = pd.DataFrame([X_importance.columns.tolist(), shap_sum.tolist()]).T\n",
    "importance_df.columns = ['column_name', 'shap_importance']\n",
    "importance_df = importance_df.sort_values('shap_importance', ascending=False)\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>shap_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>DDD_sum</td>\n",
       "      <td>0.20519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>contents_attribute_d_attribute_d_s</td>\n",
       "      <td>0.091173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>contents_attribute_d</td>\n",
       "      <td>0.079804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>contents_attribute_a</td>\n",
       "      <td>0.07621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>contents_open_hour</td>\n",
       "      <td>0.073057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           column_name shap_importance\n",
       "99                             DDD_sum         0.20519\n",
       "44  contents_attribute_d_attribute_d_s        0.091173\n",
       "24                contents_attribute_d        0.079804\n",
       "18                contents_attribute_a         0.07621\n",
       "30                  contents_open_hour        0.073057"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_df.query('shap_importance > 0.07')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importance가 0.07 이상인 피쳐만 가지고 PCA를 진행한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73966583, 0.96322691, 0.99997459, 1.        ])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca1=PCA().fit(x_test[list(importance_df.query('shap_importance > 0.07').column_name)])\n",
    "np.cumsum(pca1.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1,5), pca1.explained_variance_ratio_)\n",
    "plt.xlabel('Number of PCA')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "x_new_pca = pd.DataFrame(pca.fit_transform(x_train[list(importance_df.query('shap_importance > 0.07').column_name)]))\n",
    "x_te_new_pca = pd.DataFrame(pca.transform(x_test[list(importance_df.query('shap_importance > 0.07').column_name)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 군집의 개수는 임의로 정했다.\n",
    "# random seed를 고정안하는 실수로 완벽하게 복구가 안됨.\n",
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞에서 구한 PCA 열들만 가지고 clustering을 진행한다.\n",
    "\n",
    "train_km = km.fit_predict(x_new_pca)\n",
    "test_km = km.predict(x_te_new_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     65877\n",
       "18    49045\n",
       "11    36582\n",
       "9     35557\n",
       "8     33115\n",
       "3     32493\n",
       "1     30410\n",
       "7     26817\n",
       "2     25571\n",
       "4     25336\n",
       "6     21121\n",
       "16    20885\n",
       "10    18422\n",
       "13    17118\n",
       "15    15225\n",
       "14    15050\n",
       "5     10869\n",
       "17     9019\n",
       "19     8134\n",
       "12     5305\n",
       "Name: cl, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_km).rename(columns={0:'cl'}).cl.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     6257\n",
       "18    4357\n",
       "9     3354\n",
       "11    3225\n",
       "8     3183\n",
       "3     3090\n",
       "1     2584\n",
       "7     2544\n",
       "4     2297\n",
       "2     2221\n",
       "10    1956\n",
       "6     1934\n",
       "16    1914\n",
       "13    1509\n",
       "14    1447\n",
       "15    1331\n",
       "5     1031\n",
       "17     912\n",
       "19     785\n",
       "12     473\n",
       "Name: cl, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_km).rename(columns={0:'cl'}).cl.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['cluster1'] = train_km\n",
    "x_test['cluster1'] = test_km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat_features = x_train.columns[x_train.nunique() > 2].tolist()\n",
    "cat_features = list(set(cat_features) - set(['content_L_code_sum', 'person_prefer_mul', \n",
    "                                             'contents_attribute_mul', 'prefer_attribute_com',\n",
    "                                             'D_H_1_mul', 'D_H_2_mul', 'D_H_3_mul',\n",
    "                                             'D_H_1_sum', 'D_H_2_sum', 'D_H_3_sum',\n",
    "                                             ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(random_state=SEED, eval_metric=\"F1\", cat_features=cat_features, one_hot_max_size=4, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train[num_features] = x_train[num_features].astype(float)\n",
    "x_train[cat_features] = x_train[cat_features].astype(str)\n",
    "\n",
    "x_test[num_features] = x_test[num_features].astype(float)\n",
    "x_test[cat_features] = x_test[cat_features].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.146594\n",
      "0:\tlearn: 0.6068367\ttotal: 4.07s\tremaining: 1h 7m 45s\n",
      "100:\tlearn: 0.6696198\ttotal: 8m 15s\tremaining: 1h 13m 31s\n",
      "200:\tlearn: 0.6768241\ttotal: 16m 42s\tremaining: 1h 6m 23s\n",
      "300:\tlearn: 0.6794433\ttotal: 24m 54s\tremaining: 57m 49s\n",
      "400:\tlearn: 0.6816574\ttotal: 33m 5s\tremaining: 49m 25s\n",
      "500:\tlearn: 0.6838202\ttotal: 42m 3s\tremaining: 41m 53s\n",
      "600:\tlearn: 0.6855792\ttotal: 51m 11s\tremaining: 33m 59s\n",
      "700:\tlearn: 0.6870131\ttotal: 1h 20s\tremaining: 25m 44s\n",
      "800:\tlearn: 0.6882999\ttotal: 1h 9m 36s\tremaining: 17m 17s\n",
      "900:\tlearn: 0.6898486\ttotal: 1h 18m 29s\tremaining: 8m 37s\n",
      "999:\tlearn: 0.6910712\ttotal: 1h 27m 28s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "sfm = SelectFromModel(model, threshold='median')\n",
    "sfm.fit(x_train, y_train)\n",
    "x_new = sfm.transform(x_train)\n",
    "x_te_new = sfm.transform(x_test)\n",
    "feature_idx = sfm.get_support()\n",
    "feature_name = x_train.columns[feature_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_new = pd.DataFrame(x_new)\n",
    "x_te_new = pd.DataFrame(x_te_new)\n",
    "\n",
    "x_new.columns = feature_name\n",
    "x_te_new.columns = feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person_attribute_a_1', 'person_attribute_b', 'person_prefer_c',\n",
       "       'person_prefer_d_1', 'person_prefer_d_2', 'person_prefer_d_3',\n",
       "       'person_prefer_e', 'person_prefer_h_1', 'person_prefer_h_2',\n",
       "       'person_prefer_h_3', 'contents_attribute_a', 'contents_attribute_j_1',\n",
       "       'contents_attribute_c', 'contents_attribute_l', 'contents_attribute_d',\n",
       "       'contents_attribute_m', 'contents_attribute_e', 'contents_attribute_h',\n",
       "       'contents_open_hour', 'person_prefer_d_1_attribute_d_d',\n",
       "       'person_prefer_d_1_attribute_d_s', 'person_prefer_d_1_attribute_d_m',\n",
       "       'person_prefer_d_1_attribute_d_l', 'person_prefer_d_2_attribute_d_d',\n",
       "       'person_prefer_d_2_attribute_d_s', 'person_prefer_d_2_attribute_d_m',\n",
       "       'person_prefer_d_2_attribute_d_l', 'person_prefer_d_3_attribute_d_d',\n",
       "       'person_prefer_d_3_attribute_d_s', 'contents_attribute_d_attribute_d_d',\n",
       "       'contents_attribute_d_attribute_d_s',\n",
       "       'contents_attribute_d_attribute_d_m',\n",
       "       'contents_attribute_d_attribute_d_l', 'person_prefer_h_1_attribute_h_m',\n",
       "       'person_prefer_h_1_attribute_h_l', 'person_prefer_h_2_attribute_h_m',\n",
       "       'person_prefer_h_2_attribute_h_l', 'person_prefer_h_3_attribute_h_m',\n",
       "       'person_prefer_h_3_attribute_h_l', 'contents_attribute_h_attribute_h_m',\n",
       "       'contents_attribute_h_attribute_h_l',\n",
       "       'contents_attribute_l_attribute_l_d',\n",
       "       'contents_attribute_l_attribute_l_s',\n",
       "       'contents_attribute_l_attribute_l_m', 'person_D_code1_score',\n",
       "       'content_L_code_sum', 'D_H_1_mul', 'D_H_1_sum', 'DD_12_diff',\n",
       "       'HH_12_diff', 'DDD_sum', 'HHH_sum', 'person_contents_e_diff',\n",
       "       'D_E_1_sum', 'H_E_1_sum', 'L_E_mul', 'L_E_sum', 'j_assemble',\n",
       "       'a_assemble', 'cluster', 'person_sum_bfg', 'contents_sum_ijkm',\n",
       "       'cluster1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat_features = x_new.columns[x_new.nunique() > 2].tolist()\n",
    "cat_features = list(set(cat_features) - set(['content_L_code_sum', \n",
    "                                             'contents_attribute_mul',\n",
    "                                             'D_H_1_mul', \n",
    "                                             ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_features = ['content_L_code_sum', \n",
    "                                             'contents_attribute_mul',\n",
    "                                             'D_H_1_mul', \n",
    "                                             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501951, 63)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_holdout = False\n",
    "n_splits = 5\n",
    "iterations = 3000\n",
    "patience = 100\n",
    "\n",
    "cv = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = x_new.select_dtypes(include=['object','category']).columns.to_list()\n",
    "num_features = x_new.select_dtypes(exclude=['object','category']).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new[num_features] = x_new[num_features].astype(float)\n",
    "x_new[cat_features] = x_new[cat_features].astype(str)\n",
    "\n",
    "x_te_new[num_features] = x_te_new[num_features].astype(float)\n",
    "x_te_new[cat_features] = x_te_new[cat_features].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Learning rate set to 0.086395\n",
      "0:\tlearn: 0.6365840\ttest: 0.6364862\tbest: 0.6364862 (0)\ttotal: 2.65s\tremaining: 2h 12m 30s\n",
      "100:\tlearn: 0.6583501\ttest: 0.6854433\tbest: 0.6854433 (100)\ttotal: 5m 39s\tremaining: 2h 42m 32s\n",
      "200:\tlearn: 0.6658912\ttest: 0.6920545\tbest: 0.6921195 (199)\ttotal: 11m 12s\tremaining: 2h 36m 6s\n",
      "300:\tlearn: 0.6702596\ttest: 0.6939216\tbest: 0.6941323 (279)\ttotal: 16m 58s\tremaining: 2h 32m 14s\n",
      "400:\tlearn: 0.6731973\ttest: 0.6951032\tbest: 0.6952338 (386)\ttotal: 22m 59s\tremaining: 2h 28m 59s\n",
      "500:\tlearn: 0.6750560\ttest: 0.6951682\tbest: 0.6955369 (492)\ttotal: 28m 57s\tremaining: 2h 24m 25s\n",
      "600:\tlearn: 0.6767701\ttest: 0.6956822\tbest: 0.6958519 (558)\ttotal: 34m 59s\tremaining: 2h 19m 40s\n",
      "700:\tlearn: 0.6780208\ttest: 0.6958490\tbest: 0.6960357 (641)\ttotal: 40m 47s\tremaining: 2h 13m 47s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6960356539\n",
      "bestIteration = 641\n",
      "\n",
      "Shrink model to first 642 iterations.\n",
      "==================================================\n",
      "Learning rate set to 0.086395\n",
      "0:\tlearn: 0.6057762\ttest: 0.6088114\tbest: 0.6088114 (0)\ttotal: 2.34s\tremaining: 1h 56m 49s\n",
      "100:\tlearn: 0.6598128\ttest: 0.6811485\tbest: 0.6812779 (97)\ttotal: 6m 2s\tremaining: 2h 53m 24s\n",
      "200:\tlearn: 0.6663557\ttest: 0.6895850\tbest: 0.6895850 (200)\ttotal: 12m 5s\tremaining: 2h 48m 20s\n",
      "300:\tlearn: 0.6698988\ttest: 0.6921788\tbest: 0.6921788 (300)\ttotal: 18m 47s\tremaining: 2h 48m 30s\n",
      "400:\tlearn: 0.6726126\ttest: 0.6923561\tbest: 0.6923561 (400)\ttotal: 25m\tremaining: 2h 42m 2s\n",
      "500:\tlearn: 0.6743942\ttest: 0.6924183\tbest: 0.6927165 (486)\ttotal: 31m 17s\tremaining: 2h 36m 6s\n",
      "600:\tlearn: 0.6758956\ttest: 0.6927403\tbest: 0.6933190 (567)\ttotal: 37m 32s\tremaining: 2h 29m 49s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6933190486\n",
      "bestIteration = 567\n",
      "\n",
      "Shrink model to first 568 iterations.\n",
      "==================================================\n",
      "Learning rate set to 0.086395\n",
      "0:\tlearn: 0.6157147\ttest: 0.6207808\tbest: 0.6207808 (0)\ttotal: 2.83s\tremaining: 2h 21m 42s\n",
      "100:\tlearn: 0.6596743\ttest: 0.6801995\tbest: 0.6801995 (100)\ttotal: 6m 19s\tremaining: 3h 1m 38s\n",
      "200:\tlearn: 0.6673606\ttest: 0.6856789\tbest: 0.6856789 (200)\ttotal: 12m 37s\tremaining: 2h 55m 42s\n",
      "300:\tlearn: 0.6713511\ttest: 0.6885827\tbest: 0.6885827 (300)\ttotal: 19m\tremaining: 2h 50m 24s\n",
      "400:\tlearn: 0.6738781\ttest: 0.6892137\tbest: 0.6895193 (370)\ttotal: 25m 52s\tremaining: 2h 47m 42s\n",
      "500:\tlearn: 0.6757681\ttest: 0.6901752\tbest: 0.6902937 (492)\ttotal: 32m 17s\tremaining: 2h 41m 3s\n",
      "600:\tlearn: 0.6774779\ttest: 0.6908720\tbest: 0.6908799 (587)\ttotal: 39m 6s\tremaining: 2h 36m 6s\n",
      "700:\tlearn: 0.6791908\ttest: 0.6904956\tbest: 0.6910362 (612)\ttotal: 46m 13s\tremaining: 2h 31m 34s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6910361764\n",
      "bestIteration = 612\n",
      "\n",
      "Shrink model to first 613 iterations.\n",
      "==================================================\n",
      "Learning rate set to 0.086395\n",
      "0:\tlearn: 0.6294811\ttest: 0.6290997\tbest: 0.6290997 (0)\ttotal: 2.94s\tremaining: 2h 27m 13s\n",
      "100:\tlearn: 0.6583869\ttest: 0.6834111\tbest: 0.6834275 (99)\ttotal: 7m 24s\tremaining: 3h 32m 28s\n",
      "200:\tlearn: 0.6660722\ttest: 0.6892292\tbest: 0.6892793 (196)\ttotal: 14m 22s\tremaining: 3h 20m 7s\n",
      "300:\tlearn: 0.6706957\ttest: 0.6915316\tbest: 0.6917168 (294)\ttotal: 21m 53s\tremaining: 3h 16m 17s\n",
      "400:\tlearn: 0.6730649\ttest: 0.6923336\tbest: 0.6923336 (400)\ttotal: 29m 12s\tremaining: 3h 9m 19s\n",
      "500:\tlearn: 0.6746967\ttest: 0.6925446\tbest: 0.6926721 (496)\ttotal: 36m 37s\tremaining: 3h 2m 42s\n",
      "600:\tlearn: 0.6761894\ttest: 0.6926755\tbest: 0.6927799 (578)\ttotal: 44m 27s\tremaining: 2h 57m 28s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6927799492\n",
      "bestIteration = 578\n",
      "\n",
      "Shrink model to first 579 iterations.\n",
      "==================================================\n",
      "Learning rate set to 0.086395\n",
      "0:\tlearn: 0.6295637\ttest: 0.6269740\tbest: 0.6269740 (0)\ttotal: 3.44s\tremaining: 2h 52m 1s\n",
      "100:\tlearn: 0.6611108\ttest: 0.6816419\tbest: 0.6816419 (100)\ttotal: 7m 43s\tremaining: 3h 41m 30s\n",
      "200:\tlearn: 0.6678671\ttest: 0.6872466\tbest: 0.6873539 (195)\ttotal: 14m 32s\tremaining: 3h 22m 32s\n",
      "300:\tlearn: 0.6715961\ttest: 0.6892625\tbest: 0.6894349 (297)\ttotal: 21m 57s\tremaining: 3h 16m 51s\n",
      "400:\tlearn: 0.6734319\ttest: 0.6904135\tbest: 0.6905969 (395)\ttotal: 29m 22s\tremaining: 3h 10m 23s\n",
      "500:\tlearn: 0.6752670\ttest: 0.6903030\tbest: 0.6910788 (455)\ttotal: 36m 41s\tremaining: 3h 3m 1s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.6910787874\n",
      "bestIteration = 455\n",
      "\n",
      "Shrink model to first 456 iterations.\n"
     ]
    }
   ],
   "source": [
    "# selection 한 모델\n",
    "scores = []\n",
    "models = []\n",
    "\n",
    "for tri, vai in cv.split(x_new):\n",
    "    print(\"=\"*50)\n",
    "    preds = []\n",
    "\n",
    "    model = CatBoostClassifier(iterations=iterations, \n",
    "                               random_state=SEED,\n",
    "                               #task_type=\"GPU\",\n",
    "                               eval_metric=\"F1\",\n",
    "                               cat_features=cat_features,\n",
    "                               one_hot_max_size=4)\n",
    "    model.fit(x_new.iloc[tri], y_train[tri], \n",
    "            eval_set=[(x_new.iloc[vai], y_train[vai])], \n",
    "            early_stopping_rounds=patience,\n",
    "            verbose=100\n",
    "        )\n",
    "    \n",
    "    models.append(model)\n",
    "    scores.append(model.get_best_score()[\"validation\"][\"F1\"])\n",
    "    if is_holdout:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6960356538881984, 0.6933190485588354, 0.6910361764428071, 0.6927799491981367, 0.6910787874226144]\n",
      "0.6928499231021183\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold값 변경에 따른 검증점수 확인 및 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7174399593644343, 0.7166020584419203, 0.7166362851386358, 0.7160560516030631, 0.7143186828053254]\n",
      "0.7162106074706758\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "scores = []\n",
    "for i,(tri, vai) in enumerate( cv.split(x_new) ):\n",
    "    pred = models[i].predict_proba(x_new.iloc[vai])[:, 1]\n",
    "    pred = np.where(pred >= threshold , 1, 0)\n",
    "    score = f1_score(y_train[vai],pred)\n",
    "    scores.append(score)\n",
    "    pred = models[i].predict_proba(x_te_new)[:, 1]\n",
    "    pred_list.append(pred)\n",
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "#0.7159527624859094"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 산술평균 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.mean(pred_list, axis=0)\n",
    "pred = np.where(pred >= threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46399</th>\n",
       "      <td>46399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46400</th>\n",
       "      <td>46400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46401</th>\n",
       "      <td>46401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46402</th>\n",
       "      <td>46402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46403</th>\n",
       "      <td>46403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46404 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  target\n",
       "0          0       0\n",
       "1          1       0\n",
       "2          2       0\n",
       "3          3       0\n",
       "4          4       0\n",
       "...      ...     ...\n",
       "46399  46399       1\n",
       "46400  46400       1\n",
       "46401  46401       1\n",
       "46402  46402       1\n",
       "46403  46403       1\n",
       "\n",
       "[46404 rows x 2 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample_submission['target'] = pred\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    34308\n",
       "0    12096\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"ks_220127_0501.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame(pred_list).T).to_csv('ks_220127_0501_proba.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
